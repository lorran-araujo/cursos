{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD_RSER5Lkb5"
      },
      "source": [
        "# Projeto 2: Classificação binária brest cancer com validação cruzada e dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tP2BcEILoLB"
      },
      "source": [
        "## Etapa 1: Importação das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "Yf0FpJ35Lf-Z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import skorch # para validacao cruzada\n",
        "from skorch import NeuralNetBinaryClassifier\n",
        "import torch\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "from sklearn.model_selection import cross_val_score, train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm1n0HOPybko",
        "outputId": "e04f137a-dde2-406d-eecc-8d784f931f6c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('2.4.0+cu121', '1.0.0', '1.5.1')"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.__version__, skorch.__version__, sklearn.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0SD4dJ4MDMN"
      },
      "source": [
        "## Etapa 2: Base de dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9aIu62WMGo8",
        "outputId": "f3a2fbd7-bd10-4e06-eb67-86d039f72f86"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f5af22e3910>"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.random.seed(123)\n",
        "torch.manual_seed(123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "u49yuDE9MJs6"
      },
      "outputs": [],
      "source": [
        "previsores = pd.read_csv('./content/entradas-breast.csv')\n",
        "classe = pd.read_csv('./content/saidas-breast.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "xXo_IgFGNYwL",
        "outputId": "3342e36b-ae2f-4c22-ec0b-d90f7e0ff3fd"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.countplot(x = classe['0']);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DebmQJZD5Z3D",
        "outputId": "977fe72a-b6e5-4852-ccaf-e5f0a5e1e5dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(569, 1)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classe.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "previsores_treinamento, previsores_teste, classe_treinamento, classe_teste = train_test_split(previsores,\n",
        "                                                                                              classe,\n",
        "                                                                                              test_size = 0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "flv2JNM05QUf"
      },
      "outputs": [],
      "source": [
        "previsores = np.array(previsores_treinamento, dtype='float32')\n",
        "classe = np.array(classe_treinamento, dtype='float32').squeeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzHRBmcs5fPH",
        "outputId": "e1863b5b-6a32-46d0-b8e7-1684fcdc6e75"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(569,)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classe.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbU8a3-Z5ixA",
        "outputId": "e971ea61-593b-44d8-ae47-50d2d7f66d3c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(previsores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyVP8xUi5k-Q",
        "outputId": "6d2f4bdd-a4cc-4b3a-ae3d-cdc559c8e8b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(classe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MI0xnzWjSJg"
      },
      "source": [
        "## Etapa 3: Classe para estrutura da rede neural"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPSnLqmJyj0R"
      },
      "source": [
        "** ATUALIZAÇÃO DEZ/2021 **: na versão atual do Skorch, os resultados da rede neural devem ser retornados sem ativação, ou seja, sem a camada sigmoide no final. Com isto, a função de custo deve ser `BCEWithLogitsLoss`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "T9m_dW0I5_5p"
      },
      "outputs": [],
      "source": [
        "class classificador_torch(nn.Module): # vai herdar de nn.Module\n",
        "  def __init__(self):\n",
        "    super().__init__() # herdando todas as caracteristicas\n",
        "\n",
        "    # 30 -> 16 -> 16 -> 1\n",
        "    self.dense0 = nn.Linear(30, 16)\n",
        "    torch.nn.init.uniform_(self.dense0.weight) #inicia os pesos em distribuicao uniforme\n",
        "    self.activation0 = nn.ReLU()\n",
        "    self.dense1 = nn.Linear(16, 16)\n",
        "    torch.nn.init.uniform_(self.dense1.weight)\n",
        "    self.activation1 = nn.ReLU()\n",
        "    self.dense2 = nn.Linear(16, 1)\n",
        "    torch.nn.init.uniform_(self.dense2.weight)\n",
        "    # self.output = nn.Sigmoid() ** ATUALIZAÇÃO (ver detalhes no texto acima) **\n",
        "\n",
        "  def forward(self, X): # faz a comunicacao (ligacao) das camadas criadas acima\n",
        "    X = self.dense0(X)\n",
        "    X = self.activation0(X)\n",
        "    X = self.dense1(X)\n",
        "    X = self.activation1(X)\n",
        "    X = self.dense2(X)\n",
        "    # X = self.output(X) ** ATUALIZAÇÃO (ver detalhes no texto acima) **\n",
        "    return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kstsTBpKj3yO"
      },
      "source": [
        "## Etapa 4: Skorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "YpnhSH7z8mCH"
      },
      "outputs": [],
      "source": [
        "classificador_sklearn = NeuralNetBinaryClassifier(module=classificador_torch,\n",
        "                                                  criterion=torch.nn.BCEWithLogitsLoss, # ** ATUALIZAÇÃO **\n",
        "                                                  optimizer=torch.optim.Adam,\n",
        "                                                  lr=0.001,\n",
        "                                                  optimizer__weight_decay=0.0001,\n",
        "                                                  max_epochs=100,\n",
        "                                                  batch_size=10,\n",
        "                                                  train_split=False) #o split dos dados é cargo da validacao cruzada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5snMQs0lGRb"
      },
      "source": [
        "## Etapa 5: Validação cruzada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJqI_cFjJNk4",
        "outputId": "a8878969-8b44-45f7-a02c-dff76036ccce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m66480.6252\u001b[0m  0.1234\n",
            "      2    \u001b[36m52451.4079\u001b[0m  0.0645\n",
            "      3    \u001b[36m41004.4045\u001b[0m  0.1407\n",
            "      4    \u001b[36m31695.1769\u001b[0m  0.0521\n",
            "      5    \u001b[36m24085.6713\u001b[0m  0.0446\n",
            "      6    \u001b[36m17821.0367\u001b[0m  0.0440\n",
            "      7    \u001b[36m12596.0337\u001b[0m  0.0620\n",
            "      8     \u001b[36m8140.4832\u001b[0m  0.0587\n",
            "      9     \u001b[36m4202.6254\u001b[0m  0.0389\n",
            "     10      \u001b[36m951.2404\u001b[0m  0.0544\n",
            "     11      \u001b[36m472.3061\u001b[0m  0.0347\n",
            "     12      \u001b[36m424.5405\u001b[0m  0.0413\n",
            "     13      \u001b[36m387.4946\u001b[0m  0.0482\n",
            "     14      \u001b[36m360.9760\u001b[0m  0.0442\n",
            "     15      \u001b[36m325.6403\u001b[0m  0.0459\n",
            "     16      \u001b[36m301.2963\u001b[0m  0.0475\n",
            "     17      \u001b[36m270.5297\u001b[0m  0.0627\n",
            "     18      \u001b[36m250.5933\u001b[0m  0.0444\n",
            "     19      \u001b[36m228.7523\u001b[0m  0.0544\n",
            "     20      \u001b[36m207.9484\u001b[0m  0.0427\n",
            "     21      \u001b[36m187.4524\u001b[0m  0.0389\n",
            "     22      \u001b[36m169.5116\u001b[0m  0.0487\n",
            "     23      \u001b[36m152.9126\u001b[0m  0.0761\n",
            "     24      \u001b[36m138.9921\u001b[0m  0.0387\n",
            "     25      \u001b[36m122.8735\u001b[0m  0.0474\n",
            "     26      \u001b[36m104.6997\u001b[0m  0.0461\n",
            "     27       \u001b[36m96.1498\u001b[0m  0.0537\n",
            "     28       \u001b[36m88.1681\u001b[0m  0.0427\n",
            "     29       \u001b[36m64.1735\u001b[0m  0.0584\n",
            "     30       \u001b[36m52.6200\u001b[0m  0.0635\n",
            "     31       \u001b[36m37.5147\u001b[0m  0.0349\n",
            "     32       \u001b[36m28.2134\u001b[0m  0.0410\n",
            "     33       \u001b[36m27.9652\u001b[0m  0.0425\n",
            "     34       \u001b[36m27.7348\u001b[0m  0.0666\n",
            "     35       \u001b[36m25.4854\u001b[0m  0.0398\n",
            "     36       \u001b[36m21.6958\u001b[0m  0.0360\n",
            "     37       27.3225  0.0627\n",
            "     38       23.3721  0.0516\n",
            "     39       22.4282  0.0542\n",
            "     40       22.2316  0.0472\n",
            "     41       \u001b[36m19.5228\u001b[0m  0.0395\n",
            "     42       22.5601  0.0390\n",
            "     43       \u001b[36m18.5621\u001b[0m  0.0718\n",
            "     44       \u001b[36m12.8720\u001b[0m  0.0403\n",
            "     45       \u001b[36m11.6490\u001b[0m  0.0653\n",
            "     46        \u001b[36m9.5633\u001b[0m  0.0394\n",
            "     47        9.8582  0.0673\n",
            "     48        \u001b[36m8.2594\u001b[0m  0.0488\n",
            "     49        \u001b[36m6.7990\u001b[0m  0.0268\n",
            "     50        7.4363  0.0535\n",
            "     51        7.2610  0.0369\n",
            "     52        8.3395  0.0341\n",
            "     53        7.3331  0.0382\n",
            "     54        7.4252  0.0384\n",
            "     55        \u001b[36m4.9398\u001b[0m  0.0509\n",
            "     56        5.4283  0.0343\n",
            "     57        \u001b[36m4.1305\u001b[0m  0.0534\n",
            "     58        4.1671  0.0454\n",
            "     59        4.1897  0.0369\n",
            "     60        4.2805  0.0425\n",
            "     61        \u001b[36m3.9162\u001b[0m  0.0580\n",
            "     62        3.9541  0.0510\n",
            "     63        \u001b[36m3.8315\u001b[0m  0.0331\n",
            "     64        \u001b[36m2.9447\u001b[0m  0.0409\n",
            "     65        3.5270  0.0365\n",
            "     66        6.6968  0.0500\n",
            "     67        3.7120  0.0496\n",
            "     68        3.3155  0.0475\n",
            "     69        7.8631  0.0364\n",
            "     70        5.1009  0.0453\n",
            "     71        6.6579  0.0407\n",
            "     72        \u001b[36m2.3542\u001b[0m  0.0335\n",
            "     73        5.4863  0.0424\n",
            "     74        3.3837  0.0325\n",
            "     75        4.7051  0.0421\n",
            "     76        6.7492  0.0430\n",
            "     77        8.8044  0.0394\n",
            "     78        \u001b[36m2.0082\u001b[0m  0.0270\n",
            "     79        3.2274  0.0428\n",
            "     80        3.0386  0.0367\n",
            "     81        3.1199  0.0549\n",
            "     82        7.3617  0.0348\n",
            "     83        \u001b[36m2.0038\u001b[0m  0.0372\n",
            "     84        2.0912  0.0442\n",
            "     85        \u001b[36m1.9889\u001b[0m  0.0533\n",
            "     86        7.3867  0.0317\n",
            "     87        4.9498  0.0399\n",
            "     88        \u001b[36m1.6823\u001b[0m  0.0491\n",
            "     89        6.4755  0.0350\n",
            "     90       12.7516  0.0350\n",
            "     91        5.3686  0.0610\n",
            "     92        9.6366  0.0519\n",
            "     93        5.0085  0.0590\n",
            "     94        7.2426  0.0369\n",
            "     95        4.5299  0.0627\n",
            "     96        6.6477  0.0546\n",
            "     97        4.6456  0.0513\n",
            "     98        2.8302  0.0357\n",
            "     99        3.5205  0.0466\n",
            "    100        1.9150  0.0324\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m96349.7828\u001b[0m  0.0398\n",
            "      2    \u001b[36m77842.3715\u001b[0m  0.0346\n",
            "      3    \u001b[36m62881.2052\u001b[0m  0.0504\n",
            "      4    \u001b[36m50681.2130\u001b[0m  0.0418\n",
            "      5    \u001b[36m40689.2714\u001b[0m  0.0608\n",
            "      6    \u001b[36m32464.4624\u001b[0m  0.0450\n",
            "      7    \u001b[36m25652.4565\u001b[0m  0.0365\n",
            "      8    \u001b[36m19964.0034\u001b[0m  0.0362\n",
            "      9    \u001b[36m15153.6031\u001b[0m  0.0404\n",
            "     10    \u001b[36m10994.4341\u001b[0m  0.0254\n",
            "     11     \u001b[36m7282.2171\u001b[0m  0.0390\n",
            "     12     \u001b[36m3829.6608\u001b[0m  0.1103\n",
            "     13      \u001b[36m855.9835\u001b[0m  0.0457\n",
            "     14       \u001b[36m83.9946\u001b[0m  0.0536\n",
            "     15       \u001b[36m60.9969\u001b[0m  0.0508\n",
            "     16       \u001b[36m56.9354\u001b[0m  0.0505\n",
            "     17       \u001b[36m53.3701\u001b[0m  0.0376\n",
            "     18       \u001b[36m51.3718\u001b[0m  0.0305\n",
            "     19       \u001b[36m48.3860\u001b[0m  0.0486\n",
            "     20       \u001b[36m45.7226\u001b[0m  0.0500\n",
            "     21       \u001b[36m41.3815\u001b[0m  0.0291\n",
            "     22       \u001b[36m39.3118\u001b[0m  0.0337\n",
            "     23       \u001b[36m36.7892\u001b[0m  0.0511\n",
            "     24       \u001b[36m34.5620\u001b[0m  0.0433\n",
            "     25       \u001b[36m34.3532\u001b[0m  0.0358\n",
            "     26       \u001b[36m33.7055\u001b[0m  0.0398\n",
            "     27       \u001b[36m30.0851\u001b[0m  0.0433\n",
            "     28       \u001b[36m27.7571\u001b[0m  0.0299\n",
            "     29       \u001b[36m24.7191\u001b[0m  0.0332\n",
            "     30       \u001b[36m22.8481\u001b[0m  0.0398\n",
            "     31       \u001b[36m21.2678\u001b[0m  0.0379\n",
            "     32       \u001b[36m19.6723\u001b[0m  0.0392\n",
            "     33       \u001b[36m18.4289\u001b[0m  0.0398\n",
            "     34       \u001b[36m16.7087\u001b[0m  0.0322\n",
            "     35       \u001b[36m15.6491\u001b[0m  0.0346\n",
            "     36       \u001b[36m13.9746\u001b[0m  0.0442\n",
            "     37       \u001b[36m13.2024\u001b[0m  0.0358\n",
            "     38       \u001b[36m12.4433\u001b[0m  0.0615\n",
            "     39       \u001b[36m10.5673\u001b[0m  0.0444\n",
            "     40       10.6962  0.0294\n",
            "     41        \u001b[36m9.9985\u001b[0m  0.0477\n",
            "     42       10.3413  0.0623\n",
            "     43        \u001b[36m9.2502\u001b[0m  0.0531\n",
            "     44        \u001b[36m7.7395\u001b[0m  0.0582\n",
            "     45        8.3233  0.0486\n",
            "     46        7.9544  0.0431\n",
            "     47        \u001b[36m7.4201\u001b[0m  0.0655\n",
            "     48        7.4666  0.0770\n",
            "     49        \u001b[36m6.4518\u001b[0m  0.0432\n",
            "     50        7.0894  0.0418\n",
            "     51        6.6230  0.0543\n",
            "     52        \u001b[36m6.1422\u001b[0m  0.0387\n",
            "     53        6.5563  0.0406\n",
            "     54        \u001b[36m5.6190\u001b[0m  0.0417\n",
            "     55        5.9433  0.0446\n",
            "     56        5.9685  0.0359\n",
            "     57        5.9995  0.0510\n",
            "     58        5.9076  0.0669\n",
            "     59        9.4605  0.0453\n",
            "     60        \u001b[36m4.8409\u001b[0m  0.0466\n",
            "     61        \u001b[36m4.6242\u001b[0m  0.0493\n",
            "     62        5.3998  0.0497\n",
            "     63        5.0808  0.0538\n",
            "     64        5.0515  0.0470\n",
            "     65        5.4532  0.0321\n",
            "     66        4.6909  0.0405\n",
            "     67        \u001b[36m4.5180\u001b[0m  0.0388\n",
            "     68        5.4864  0.0448\n",
            "     69        6.0361  0.0553\n",
            "     70        4.5998  0.0500\n",
            "     71        4.7043  0.0409\n",
            "     72        4.5845  0.0423\n",
            "     73        \u001b[36m4.1646\u001b[0m  0.0505\n",
            "     74        4.4253  0.0376\n",
            "     75        \u001b[36m3.7154\u001b[0m  0.0462\n",
            "     76        3.9415  0.0355\n",
            "     77        4.5058  0.0523\n",
            "     78        \u001b[36m3.2919\u001b[0m  0.0652\n",
            "     79        5.4176  0.0410\n",
            "     80        9.8813  0.0354\n",
            "     81       10.9260  0.0317\n",
            "     82        8.1616  0.0407\n",
            "     83        6.9949  0.0418\n",
            "     84        4.4518  0.0350\n",
            "     85        5.5453  0.0435\n",
            "     86        5.9570  0.0417\n",
            "     87        3.5078  0.0319\n",
            "     88        3.8271  0.0343\n",
            "     89        4.2874  0.0447\n",
            "     90        3.4272  0.0486\n",
            "     91        4.9972  0.0453\n",
            "     92        6.6628  0.0359\n",
            "     93        5.9050  0.0395\n",
            "     94        4.4171  0.0277\n",
            "     95        5.7227  0.0467\n",
            "     96        7.5086  0.0353\n",
            "     97        3.5985  0.1202\n",
            "     98        3.4305  0.0307\n",
            "     99        \u001b[36m2.9395\u001b[0m  0.0310\n",
            "    100        4.2512  0.0394\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m87140.7053\u001b[0m  0.0472\n",
            "      2    \u001b[36m70401.2439\u001b[0m  0.0385\n",
            "      3    \u001b[36m56814.8855\u001b[0m  0.0307\n",
            "      4    \u001b[36m45801.5957\u001b[0m  0.0363\n",
            "      5    \u001b[36m36847.5915\u001b[0m  0.0320\n",
            "      6    \u001b[36m29493.7302\u001b[0m  0.0386\n",
            "      7    \u001b[36m23335.8248\u001b[0m  0.0478\n",
            "      8    \u001b[36m18103.3489\u001b[0m  0.0374\n",
            "      9    \u001b[36m13597.5806\u001b[0m  0.0419\n",
            "     10     \u001b[36m9649.9276\u001b[0m  0.0367\n",
            "     11     \u001b[36m6095.1933\u001b[0m  0.0360\n",
            "     12     \u001b[36m2768.7785\u001b[0m  0.0499\n",
            "     13      \u001b[36m416.5147\u001b[0m  0.0306\n",
            "     14      \u001b[36m306.8921\u001b[0m  0.0314\n",
            "     15      \u001b[36m274.7305\u001b[0m  0.0470\n",
            "     16      \u001b[36m247.8746\u001b[0m  0.0356\n",
            "     17      \u001b[36m218.5538\u001b[0m  0.0338\n",
            "     18      \u001b[36m187.2426\u001b[0m  0.0588\n",
            "     19      \u001b[36m154.4206\u001b[0m  0.0545\n",
            "     20      \u001b[36m120.0127\u001b[0m  0.0365\n",
            "     21       \u001b[36m92.2503\u001b[0m  0.0404\n",
            "     22       \u001b[36m76.6051\u001b[0m  0.0724\n",
            "     23       \u001b[36m66.0269\u001b[0m  0.0339\n",
            "     24       \u001b[36m60.0497\u001b[0m  0.0506\n",
            "     25       \u001b[36m55.7580\u001b[0m  0.0450\n",
            "     26       \u001b[36m53.1877\u001b[0m  0.0514\n",
            "     27       \u001b[36m49.3133\u001b[0m  0.0440\n",
            "     28       \u001b[36m46.7004\u001b[0m  0.0358\n",
            "     29       \u001b[36m44.3491\u001b[0m  0.0431\n",
            "     30       \u001b[36m41.8327\u001b[0m  0.0360\n",
            "     31       \u001b[36m39.3788\u001b[0m  0.0545\n",
            "     32       \u001b[36m38.5119\u001b[0m  0.0406\n",
            "     33       \u001b[36m35.1934\u001b[0m  0.0434\n",
            "     34       \u001b[36m33.5977\u001b[0m  0.0512\n",
            "     35       \u001b[36m31.5854\u001b[0m  0.0327\n",
            "     36       \u001b[36m29.7168\u001b[0m  0.0327\n",
            "     37       \u001b[36m28.4529\u001b[0m  0.0499\n",
            "     38       \u001b[36m27.7301\u001b[0m  0.0619\n",
            "     39       \u001b[36m26.6448\u001b[0m  0.0375\n",
            "     40       \u001b[36m25.2688\u001b[0m  0.0534\n",
            "     41       \u001b[36m24.7352\u001b[0m  0.0425\n",
            "     42       \u001b[36m23.3563\u001b[0m  0.0355\n",
            "     43       \u001b[36m22.5707\u001b[0m  0.0410\n",
            "     44       \u001b[36m21.7283\u001b[0m  0.0395\n",
            "     45       21.9322  0.0459\n",
            "     46       \u001b[36m20.7320\u001b[0m  0.0382\n",
            "     47       \u001b[36m19.7630\u001b[0m  0.0530\n",
            "     48       \u001b[36m18.6481\u001b[0m  0.0435\n",
            "     49       \u001b[36m18.1156\u001b[0m  0.0444\n",
            "     50       \u001b[36m17.7341\u001b[0m  0.0472\n",
            "     51       \u001b[36m17.0977\u001b[0m  0.0473\n",
            "     52       17.6302  0.0459\n",
            "     53       \u001b[36m16.3214\u001b[0m  0.0519\n",
            "     54       \u001b[36m15.9334\u001b[0m  0.0450\n",
            "     55       \u001b[36m15.2792\u001b[0m  0.0476\n",
            "     56       \u001b[36m14.7815\u001b[0m  0.0750\n",
            "     57       15.3017  0.0442\n",
            "     58       15.6213  0.0520\n",
            "     59       \u001b[36m13.6810\u001b[0m  0.0467\n",
            "     60       14.3315  0.0572\n",
            "     61       13.8239  0.0368\n",
            "     62       \u001b[36m12.5337\u001b[0m  0.0481\n",
            "     63       \u001b[36m12.0954\u001b[0m  0.0421\n",
            "     64       12.3480  0.0359\n",
            "     65       \u001b[36m11.6867\u001b[0m  0.0400\n",
            "     66       11.8465  0.0427\n",
            "     67       \u001b[36m11.5430\u001b[0m  0.0328\n",
            "     68       \u001b[36m10.9819\u001b[0m  0.0466\n",
            "     69       13.6403  0.0472\n",
            "     70       \u001b[36m10.5536\u001b[0m  0.0343\n",
            "     71       \u001b[36m10.5192\u001b[0m  0.0395\n",
            "     72       \u001b[36m10.1151\u001b[0m  0.0468\n",
            "     73       10.8077  0.0948\n",
            "     74       10.8701  0.0447\n",
            "     75        \u001b[36m8.9902\u001b[0m  0.0818\n",
            "     76        \u001b[36m8.9361\u001b[0m  0.0543\n",
            "     77        9.8372  0.0635\n",
            "     78        \u001b[36m7.1056\u001b[0m  0.0624\n",
            "     79        8.4918  0.0488\n",
            "     80        \u001b[36m6.8445\u001b[0m  0.0527\n",
            "     81        \u001b[36m5.6776\u001b[0m  0.0455\n",
            "     82        \u001b[36m5.4444\u001b[0m  0.0536\n",
            "     83        \u001b[36m4.6882\u001b[0m  0.0499\n",
            "     84       17.1680  0.0314\n",
            "     85        6.4587  0.0332\n",
            "     86        7.7959  0.0369\n",
            "     87        6.2216  0.0429\n",
            "     88        7.8219  0.0476\n",
            "     89        4.9617  0.0456\n",
            "     90        \u001b[36m3.6479\u001b[0m  0.0580\n",
            "     91        4.2505  0.0511\n",
            "     92        4.3694  0.0357\n",
            "     93        4.9803  0.0657\n",
            "     94        8.6119  0.0466\n",
            "     95        \u001b[36m3.5228\u001b[0m  0.0803\n",
            "     96        3.6852  0.0353\n",
            "     97        8.4376  0.0411\n",
            "     98        7.4567  0.0435\n",
            "     99        4.8454  0.0364\n",
            "    100        \u001b[36m3.3336\u001b[0m  0.0300\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m93982.9732\u001b[0m  0.0543\n",
            "      2    \u001b[36m76344.5253\u001b[0m  0.0393\n",
            "      3    \u001b[36m61940.2863\u001b[0m  0.0338\n",
            "      4    \u001b[36m50142.0566\u001b[0m  0.0666\n",
            "      5    \u001b[36m40422.2258\u001b[0m  0.1580\n",
            "      6    \u001b[36m32385.5137\u001b[0m  0.0600\n",
            "      7    \u001b[36m25746.2384\u001b[0m  0.0447\n",
            "      8    \u001b[36m20244.0053\u001b[0m  0.0403\n",
            "      9    \u001b[36m15660.2574\u001b[0m  0.0769\n",
            "     10    \u001b[36m11797.2523\u001b[0m  0.0757\n",
            "     11     \u001b[36m8474.1475\u001b[0m  0.0992\n",
            "     12     \u001b[36m5530.8494\u001b[0m  0.0599\n",
            "     13     \u001b[36m2822.2585\u001b[0m  0.0795\n",
            "     14      \u001b[36m533.9981\u001b[0m  0.0700\n",
            "     15      \u001b[36m154.9030\u001b[0m  0.0566\n",
            "     16      \u001b[36m119.8259\u001b[0m  0.0607\n",
            "     17       \u001b[36m95.9476\u001b[0m  0.0588\n",
            "     18       \u001b[36m82.4113\u001b[0m  0.0656\n",
            "     19       \u001b[36m76.6235\u001b[0m  0.0837\n",
            "     20       \u001b[36m68.9251\u001b[0m  0.0727\n",
            "     21       \u001b[36m65.5146\u001b[0m  0.0862\n",
            "     22       \u001b[36m61.5749\u001b[0m  0.0554\n",
            "     23       \u001b[36m58.8293\u001b[0m  0.0630\n",
            "     24       \u001b[36m55.7246\u001b[0m  0.0657\n",
            "     25       \u001b[36m53.8459\u001b[0m  0.1235\n",
            "     26       \u001b[36m50.7579\u001b[0m  0.0919\n",
            "     27       \u001b[36m47.3878\u001b[0m  0.0466\n",
            "     28       \u001b[36m45.2765\u001b[0m  0.0919\n",
            "     29       \u001b[36m44.1826\u001b[0m  0.0397\n",
            "     30       \u001b[36m41.1965\u001b[0m  0.0998\n",
            "     31       42.4999  0.0663\n",
            "     32       42.3230  0.0402\n",
            "     33       \u001b[36m36.4424\u001b[0m  0.0264\n",
            "     34       \u001b[36m33.3384\u001b[0m  0.0424\n",
            "     35       \u001b[36m32.9144\u001b[0m  0.0495\n",
            "     36       \u001b[36m31.5045\u001b[0m  0.0740\n",
            "     37       \u001b[36m30.8825\u001b[0m  0.0535\n",
            "     38       \u001b[36m29.1095\u001b[0m  0.0509\n",
            "     39       \u001b[36m28.3668\u001b[0m  0.0320\n",
            "     40       \u001b[36m26.6222\u001b[0m  0.0411\n",
            "     41       \u001b[36m25.1644\u001b[0m  0.0394\n",
            "     42       25.5061  0.0414\n",
            "     43       \u001b[36m23.5220\u001b[0m  0.0446\n",
            "     44       \u001b[36m22.6958\u001b[0m  0.0479\n",
            "     45       23.4123  0.0733\n",
            "     46       23.1126  0.0648\n",
            "     47       \u001b[36m20.4289\u001b[0m  0.0424\n",
            "     48       \u001b[36m20.0866\u001b[0m  0.0409\n",
            "     49       20.6016  0.0419\n",
            "     50       \u001b[36m19.0279\u001b[0m  0.0360\n",
            "     51       20.0311  0.0342\n",
            "     52       \u001b[36m18.1836\u001b[0m  0.0559\n",
            "     53       \u001b[36m17.6302\u001b[0m  0.0959\n",
            "     54       \u001b[36m16.6057\u001b[0m  0.0847\n",
            "     55       \u001b[36m16.2184\u001b[0m  0.0414\n",
            "     56       \u001b[36m14.5484\u001b[0m  0.0430\n",
            "     57       15.1775  0.0559\n",
            "     58       \u001b[36m13.6846\u001b[0m  0.0495\n",
            "     59       \u001b[36m12.6596\u001b[0m  0.1020\n",
            "     60       \u001b[36m12.3476\u001b[0m  0.0637\n",
            "     61       12.4240  0.0374\n",
            "     62       \u001b[36m12.0284\u001b[0m  0.0274\n",
            "     63       12.4233  0.0387\n",
            "     64       \u001b[36m11.7401\u001b[0m  0.0387\n",
            "     65       \u001b[36m10.6345\u001b[0m  0.0360\n",
            "     66        \u001b[36m9.7958\u001b[0m  0.0466\n",
            "     67        9.8709  0.0551\n",
            "     68        \u001b[36m9.6902\u001b[0m  0.0395\n",
            "     69        \u001b[36m9.0816\u001b[0m  0.0578\n",
            "     70        \u001b[36m8.9553\u001b[0m  0.0600\n",
            "     71        \u001b[36m8.5588\u001b[0m  0.0578\n",
            "     72        8.6688  0.0450\n",
            "     73        8.5748  0.0328\n",
            "     74       10.2297  0.0354\n",
            "     75        \u001b[36m7.2230\u001b[0m  0.0351\n",
            "     76        7.3359  0.0455\n",
            "     77        8.0235  0.0621\n",
            "     78        \u001b[36m5.4248\u001b[0m  0.0647\n",
            "     79        6.9972  0.0511\n",
            "     80        5.4323  0.0704\n",
            "     81        \u001b[36m4.9243\u001b[0m  0.0489\n",
            "     82        4.9325  0.0389\n",
            "     83        5.1775  0.0397\n",
            "     84        7.7215  0.0474\n",
            "     85        5.0087  0.0591\n",
            "     86        \u001b[36m3.9615\u001b[0m  0.0769\n",
            "     87        6.1387  0.0460\n",
            "     88        7.8910  0.0651\n",
            "     89        5.0986  0.0357\n",
            "     90        4.9536  0.0514\n",
            "     91        4.2296  0.0465\n",
            "     92        \u001b[36m3.7164\u001b[0m  0.0440\n",
            "     93        6.4000  0.0377\n",
            "     94        4.8457  0.0279\n",
            "     95        4.1486  0.0507\n",
            "     96        \u001b[36m3.5111\u001b[0m  0.0572\n",
            "     97        4.3342  0.0852\n",
            "     98        3.6171  0.1140\n",
            "     99        \u001b[36m3.2743\u001b[0m  0.0809\n",
            "    100        3.3813  0.0297\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m76599.7868\u001b[0m  0.0387\n",
            "      2    \u001b[36m60973.5239\u001b[0m  0.0378\n",
            "      3    \u001b[36m48343.0906\u001b[0m  0.0338\n",
            "      4    \u001b[36m38045.7756\u001b[0m  0.0414\n",
            "      5    \u001b[36m29582.5461\u001b[0m  0.0655\n",
            "      6    \u001b[36m22520.7398\u001b[0m  0.0396\n",
            "      7    \u001b[36m16525.4043\u001b[0m  0.0363\n",
            "      8    \u001b[36m11331.6107\u001b[0m  0.0429\n",
            "      9     \u001b[36m6697.0499\u001b[0m  0.0661\n",
            "     10     \u001b[36m2376.9959\u001b[0m  0.0411\n",
            "     11      \u001b[36m277.0968\u001b[0m  0.0534\n",
            "     12      \u001b[36m219.4808\u001b[0m  0.0491\n",
            "     13      \u001b[36m194.5178\u001b[0m  0.0396\n",
            "     14      \u001b[36m157.5497\u001b[0m  0.0621\n",
            "     15      \u001b[36m127.4807\u001b[0m  0.0711\n",
            "     16       \u001b[36m97.8096\u001b[0m  0.1056\n",
            "     17       \u001b[36m71.6500\u001b[0m  0.0643\n",
            "     18       \u001b[36m48.7020\u001b[0m  0.0678\n",
            "     19       \u001b[36m37.4286\u001b[0m  0.0555\n",
            "     20       \u001b[36m30.7062\u001b[0m  0.0528\n",
            "     21       \u001b[36m24.5095\u001b[0m  0.0683\n",
            "     22       \u001b[36m22.0606\u001b[0m  0.0413\n",
            "     23       \u001b[36m20.9877\u001b[0m  0.0822\n",
            "     24       \u001b[36m20.3916\u001b[0m  0.0748\n",
            "     25       \u001b[36m19.6047\u001b[0m  0.0437\n",
            "     26       \u001b[36m18.9275\u001b[0m  0.0438\n",
            "     27       \u001b[36m18.6749\u001b[0m  0.0718\n",
            "     28       21.2756  0.0499\n",
            "     29       21.9071  0.0572\n",
            "     30       21.3438  0.0429\n",
            "     31       20.0096  0.0603\n",
            "     32       \u001b[36m16.5026\u001b[0m  0.0680\n",
            "     33       \u001b[36m15.9258\u001b[0m  0.0467\n",
            "     34       \u001b[36m15.8615\u001b[0m  0.0759\n",
            "     35       \u001b[36m14.6674\u001b[0m  0.0592\n",
            "     36       15.1730  0.0396\n",
            "     37       \u001b[36m13.5823\u001b[0m  0.0285\n",
            "     38       14.3230  0.0640\n",
            "     39       14.4859  0.0520\n",
            "     40       13.9060  0.0284\n",
            "     41       \u001b[36m11.9431\u001b[0m  0.0334\n",
            "     42       12.8806  0.0379\n",
            "     43       13.4791  0.0344\n",
            "     44       12.2056  0.0337\n",
            "     45       11.9518  0.0415\n",
            "     46       \u001b[36m10.7144\u001b[0m  0.0278\n",
            "     47       \u001b[36m10.3448\u001b[0m  0.0335\n",
            "     48       12.5649  0.0435\n",
            "     49       \u001b[36m10.2038\u001b[0m  0.0403\n",
            "     50       10.2996  0.0505\n",
            "     51       10.7992  0.0404\n",
            "     52       10.5207  0.0367\n",
            "     53        \u001b[36m7.8616\u001b[0m  0.0408\n",
            "     54       11.3443  0.0568\n",
            "     55       11.4852  0.0557\n",
            "     56        \u001b[36m6.0235\u001b[0m  0.0318\n",
            "     57        9.1012  0.0439\n",
            "     58        8.4125  0.0355\n",
            "     59        6.4474  0.0377\n",
            "     60        \u001b[36m3.7061\u001b[0m  0.0363\n",
            "     61        4.0800  0.0476\n",
            "     62        \u001b[36m3.1965\u001b[0m  0.0390\n",
            "     63        4.2502  0.0583\n",
            "     64        5.8460  0.0859\n",
            "     65       10.5947  0.0424\n",
            "     66       11.8516  0.0303\n",
            "     67       13.1903  0.0557\n",
            "     68       12.4757  0.0413\n",
            "     69       10.5345  0.0302\n",
            "     70        4.6129  0.0503\n",
            "     71        3.4813  0.0543\n",
            "     72        \u001b[36m2.4679\u001b[0m  0.0330\n",
            "     73        \u001b[36m2.3047\u001b[0m  0.0487\n",
            "     74        2.9405  0.0374\n",
            "     75        3.0268  0.0304\n",
            "     76        2.4643  0.0449\n",
            "     77        2.9807  0.0603\n",
            "     78        \u001b[36m2.1124\u001b[0m  0.0638\n",
            "     79        3.0735  0.0410\n",
            "     80        4.1941  0.0649\n",
            "     81        4.5556  0.0416\n",
            "     82        3.1516  0.0434\n",
            "     83        2.9905  0.0447\n",
            "     84        3.4252  0.0345\n",
            "     85        2.9670  0.0355\n",
            "     86        3.6443  0.0454\n",
            "     87        2.6279  0.0528\n",
            "     88        2.9050  0.0415\n",
            "     89        4.8514  0.0510\n",
            "     90        2.2605  0.0393\n",
            "     91        4.3515  0.0381\n",
            "     92        8.7135  0.0347\n",
            "     93        2.9981  0.0360\n",
            "     94        2.6665  0.0317\n",
            "     95       11.8533  0.0325\n",
            "     96        5.1323  0.0381\n",
            "     97        2.5869  0.0262\n",
            "     98        4.0224  0.0353\n",
            "     99        2.6589  0.0354\n",
            "    100        3.9666  0.0524\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m78432.7740\u001b[0m  0.0387\n",
            "      2    \u001b[36m62611.4833\u001b[0m  0.0324\n",
            "      3    \u001b[36m49785.7708\u001b[0m  0.0396\n",
            "      4    \u001b[36m39303.4223\u001b[0m  0.0476\n",
            "      5    \u001b[36m30608.2314\u001b[0m  0.0384\n",
            "      6    \u001b[36m23265.9280\u001b[0m  0.0302\n",
            "      7    \u001b[36m16947.5114\u001b[0m  0.0362\n",
            "      8    \u001b[36m11382.8746\u001b[0m  0.0267\n",
            "      9     \u001b[36m6305.8614\u001b[0m  0.0432\n",
            "     10     \u001b[36m1564.5865\u001b[0m  0.0424\n",
            "     11      \u001b[36m180.8161\u001b[0m  0.0286\n",
            "     12       \u001b[36m99.6250\u001b[0m  0.0353\n",
            "     13       \u001b[36m94.3474\u001b[0m  0.0303\n",
            "     14       \u001b[36m86.7621\u001b[0m  0.0302\n",
            "     15       \u001b[36m79.5626\u001b[0m  0.0333\n",
            "     16       \u001b[36m74.7944\u001b[0m  0.0345\n",
            "     17       \u001b[36m66.6406\u001b[0m  0.0256\n",
            "     18       \u001b[36m61.0125\u001b[0m  0.0339\n",
            "     19       \u001b[36m55.1845\u001b[0m  0.0367\n",
            "     20       \u001b[36m49.4720\u001b[0m  0.0378\n",
            "     21       \u001b[36m47.4164\u001b[0m  0.0412\n",
            "     22       \u001b[36m45.3950\u001b[0m  0.0494\n",
            "     23       \u001b[36m44.4786\u001b[0m  0.0575\n",
            "     24       \u001b[36m43.3111\u001b[0m  0.0477\n",
            "     25       \u001b[36m39.9892\u001b[0m  0.0372\n",
            "     26       \u001b[36m38.5932\u001b[0m  0.0347\n",
            "     27       \u001b[36m37.1416\u001b[0m  0.0296\n",
            "     28       \u001b[36m36.0175\u001b[0m  0.0562\n",
            "     29       36.6227  0.0445\n",
            "     30       \u001b[36m33.8772\u001b[0m  0.0369\n",
            "     31       \u001b[36m31.9959\u001b[0m  0.0447\n",
            "     32       \u001b[36m29.2908\u001b[0m  0.0456\n",
            "     33       30.3496  0.0344\n",
            "     34       \u001b[36m25.0020\u001b[0m  0.0328\n",
            "     35       29.2455  0.0344\n",
            "     36       26.6954  0.0412\n",
            "     37       \u001b[36m22.5091\u001b[0m  0.0317\n",
            "     38       22.9180  0.0450\n",
            "     39       22.5372  0.0429\n",
            "     40       \u001b[36m20.1185\u001b[0m  0.0333\n",
            "     41       21.6148  0.0403\n",
            "     42       \u001b[36m18.1183\u001b[0m  0.0362\n",
            "     43       \u001b[36m16.1784\u001b[0m  0.0321\n",
            "     44       \u001b[36m16.0707\u001b[0m  0.0351\n",
            "     45       \u001b[36m14.8409\u001b[0m  0.0321\n",
            "     46       \u001b[36m12.2801\u001b[0m  0.0304\n",
            "     47       13.6077  0.0412\n",
            "     48       12.5159  0.0656\n",
            "     49       12.6760  0.0507\n",
            "     50       \u001b[36m11.7938\u001b[0m  0.0457\n",
            "     51       12.9364  0.0372\n",
            "     52        \u001b[36m9.8545\u001b[0m  0.0352\n",
            "     53        \u001b[36m9.4812\u001b[0m  0.0360\n",
            "     54        \u001b[36m8.3130\u001b[0m  0.0478\n",
            "     55        \u001b[36m7.2577\u001b[0m  0.0519\n",
            "     56        8.2151  0.0399\n",
            "     57        \u001b[36m6.9910\u001b[0m  0.0350\n",
            "     58        7.0552  0.0371\n",
            "     59        7.1882  0.0529\n",
            "     60        8.2693  0.0393\n",
            "     61        \u001b[36m6.1948\u001b[0m  0.0312\n",
            "     62        \u001b[36m6.1656\u001b[0m  0.0414\n",
            "     63        \u001b[36m5.2747\u001b[0m  0.0504\n",
            "     64        5.7985  0.0497\n",
            "     65        6.4379  0.0429\n",
            "     66        \u001b[36m4.6251\u001b[0m  0.0594\n",
            "     67        5.5188  0.1162\n",
            "     68        \u001b[36m4.4995\u001b[0m  0.0309\n",
            "     69        \u001b[36m4.3106\u001b[0m  0.0423\n",
            "     70        \u001b[36m4.1664\u001b[0m  0.0620\n",
            "     71        6.0613  0.0403\n",
            "     72        4.3214  0.0384\n",
            "     73        4.2440  0.0523\n",
            "     74        8.9959  0.0753\n",
            "     75        \u001b[36m3.5202\u001b[0m  0.0510\n",
            "     76        5.3497  0.0680\n",
            "     77        4.5966  0.0801\n",
            "     78        \u001b[36m2.9907\u001b[0m  0.0579\n",
            "     79       12.1972  0.0260\n",
            "     80        3.6641  0.0486\n",
            "     81        5.3777  0.0405\n",
            "     82        5.1367  0.0361\n",
            "     83       15.2786  0.0327\n",
            "     84        7.2251  0.0319\n",
            "     85        \u001b[36m2.6809\u001b[0m  0.0490\n",
            "     86        3.6261  0.0355\n",
            "     87        8.2696  0.0392\n",
            "     88        9.4491  0.0349\n",
            "     89        5.2455  0.0358\n",
            "     90        3.2154  0.0377\n",
            "     91        3.9815  0.0385\n",
            "     92        3.1714  0.0435\n",
            "     93        3.1011  0.0436\n",
            "     94        \u001b[36m2.2696\u001b[0m  0.0438\n",
            "     95        3.1676  0.0504\n",
            "     96        7.7987  0.0636\n",
            "     97        6.3724  0.0514\n",
            "     98        2.4708  0.0443\n",
            "     99        3.5569  0.0369\n",
            "    100        7.5896  0.0364\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m65321.1823\u001b[0m  0.0433\n",
            "      2    \u001b[36m50829.0176\u001b[0m  0.0429\n",
            "      3    \u001b[36m39327.6936\u001b[0m  0.0703\n",
            "      4    \u001b[36m30172.1878\u001b[0m  0.0515\n",
            "      5    \u001b[36m22829.6262\u001b[0m  0.0534\n",
            "      6    \u001b[36m16872.7655\u001b[0m  0.0357\n",
            "      7    \u001b[36m11942.7032\u001b[0m  0.0255\n",
            "      8     \u001b[36m7731.3411\u001b[0m  0.0539\n",
            "      9     \u001b[36m3959.6645\u001b[0m  0.0869\n",
            "     10      \u001b[36m704.1025\u001b[0m  0.0418\n",
            "     11      \u001b[36m158.8781\u001b[0m  0.0662\n",
            "     12      \u001b[36m135.6162\u001b[0m  0.0526\n",
            "     13      \u001b[36m117.2230\u001b[0m  0.0898\n",
            "     14      \u001b[36m100.0639\u001b[0m  0.0833\n",
            "     15       \u001b[36m83.2489\u001b[0m  0.0793\n",
            "     16       \u001b[36m66.7879\u001b[0m  0.0750\n",
            "     17       \u001b[36m55.3322\u001b[0m  0.0529\n",
            "     18       \u001b[36m42.8728\u001b[0m  0.0852\n",
            "     19       \u001b[36m33.9443\u001b[0m  0.0729\n",
            "     20       \u001b[36m32.7227\u001b[0m  0.0533\n",
            "     21       \u001b[36m28.4904\u001b[0m  0.0428\n",
            "     22       31.7203  0.0471\n",
            "     23       \u001b[36m24.4990\u001b[0m  0.0515\n",
            "     24       \u001b[36m22.6099\u001b[0m  0.0599\n",
            "     25       \u001b[36m19.3403\u001b[0m  0.0593\n",
            "     26       \u001b[36m17.0301\u001b[0m  0.0618\n",
            "     27       17.2932  0.0558\n",
            "     28       \u001b[36m12.5413\u001b[0m  0.0501\n",
            "     29       18.5497  0.0680\n",
            "     30       13.8111  0.0396\n",
            "     31       \u001b[36m12.2898\u001b[0m  0.0410\n",
            "     32       \u001b[36m11.2922\u001b[0m  0.0438\n",
            "     33       \u001b[36m10.3568\u001b[0m  0.0419\n",
            "     34       10.5299  0.0368\n",
            "     35        \u001b[36m9.2501\u001b[0m  0.0477\n",
            "     36        \u001b[36m7.3295\u001b[0m  0.0420\n",
            "     37        8.7347  0.0442\n",
            "     38        \u001b[36m5.5373\u001b[0m  0.0326\n",
            "     39        7.5967  0.0374\n",
            "     40        \u001b[36m5.1819\u001b[0m  0.0422\n",
            "     41        5.7738  0.0465\n",
            "     42        \u001b[36m4.8368\u001b[0m  0.0285\n",
            "     43        \u001b[36m4.3339\u001b[0m  0.0458\n",
            "     44        4.3401  0.0493\n",
            "     45        4.4336  0.0393\n",
            "     46        \u001b[36m3.5024\u001b[0m  0.0365\n",
            "     47        4.0904  0.0329\n",
            "     48        4.5516  0.0493\n",
            "     49        \u001b[36m3.4710\u001b[0m  0.0384\n",
            "     50        3.6210  0.0589\n",
            "     51        \u001b[36m3.3133\u001b[0m  0.0650\n",
            "     52        4.6432  0.0517\n",
            "     53        3.4043  0.0473\n",
            "     54        \u001b[36m3.3009\u001b[0m  0.0403\n",
            "     55        5.1375  0.0542\n",
            "     56        7.7096  0.0382\n",
            "     57        4.0246  0.0463\n",
            "     58        3.8190  0.0550\n",
            "     59        \u001b[36m2.6872\u001b[0m  0.0388\n",
            "     60        3.8458  0.0364\n",
            "     61        9.7737  0.0453\n",
            "     62        3.5525  0.0427\n",
            "     63        6.5571  0.0510\n",
            "     64        3.0688  0.0361\n",
            "     65       10.2024  0.0325\n",
            "     66        5.0972  0.0330\n",
            "     67        4.8239  0.0424\n",
            "     68        2.8566  0.0393\n",
            "     69        3.0900  0.0297\n",
            "     70        \u001b[36m2.4158\u001b[0m  0.0417\n",
            "     71        \u001b[36m2.3495\u001b[0m  0.0446\n",
            "     72        2.6399  0.0264\n",
            "     73       10.4909  0.0358\n",
            "     74        7.4624  0.0448\n",
            "     75        3.2185  0.0501\n",
            "     76        3.2148  0.0410\n",
            "     77        3.6637  0.0633\n",
            "     78       10.1828  0.0484\n",
            "     79        4.8574  0.0398\n",
            "     80        3.9072  0.0361\n",
            "     81        2.6864  0.0340\n",
            "     82        4.7538  0.0488\n",
            "     83        4.6423  0.0592\n",
            "     84        2.9205  0.0452\n",
            "     85        5.2328  0.0334\n",
            "     86        4.4891  0.0358\n",
            "     87        5.4381  0.0401\n",
            "     88        3.7179  0.0556\n",
            "     89        5.2061  0.0470\n",
            "     90        3.8655  0.0411\n",
            "     91        3.3618  0.0388\n",
            "     92        \u001b[36m2.2680\u001b[0m  0.0350\n",
            "     93        3.6588  0.0473\n",
            "     94        5.3223  0.0332\n",
            "     95        4.4484  0.0449\n",
            "     96        4.2541  0.0396\n",
            "     97        4.8667  0.0529\n",
            "     98        3.6553  0.0478\n",
            "     99        2.8127  0.0412\n",
            "    100        4.2747  0.0342\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m78919.0424\u001b[0m  0.0444\n",
            "      2    \u001b[36m62921.8493\u001b[0m  0.0390\n",
            "      3    \u001b[36m50135.7892\u001b[0m  0.0586\n",
            "      4    \u001b[36m39898.5275\u001b[0m  0.0749\n",
            "      5    \u001b[36m31627.0646\u001b[0m  0.0526\n",
            "      6    \u001b[36m24853.9623\u001b[0m  0.0731\n",
            "      7    \u001b[36m19212.9188\u001b[0m  0.0539\n",
            "      8    \u001b[36m14422.6665\u001b[0m  0.0455\n",
            "      9    \u001b[36m10271.6983\u001b[0m  0.0655\n",
            "     10     \u001b[36m6561.8993\u001b[0m  0.0415\n",
            "     11     \u001b[36m3058.6385\u001b[0m  0.0309\n",
            "     12      \u001b[36m514.5382\u001b[0m  0.0516\n",
            "     13      \u001b[36m286.2874\u001b[0m  0.0548\n",
            "     14      \u001b[36m212.2137\u001b[0m  0.0414\n",
            "     15      \u001b[36m167.4713\u001b[0m  0.0429\n",
            "     16      \u001b[36m144.6736\u001b[0m  0.0363\n",
            "     17      \u001b[36m126.8020\u001b[0m  0.0350\n",
            "     18      \u001b[36m113.6911\u001b[0m  0.0486\n",
            "     19      \u001b[36m101.8845\u001b[0m  0.0313\n",
            "     20       \u001b[36m92.0493\u001b[0m  0.0416\n",
            "     21       \u001b[36m82.4098\u001b[0m  0.0455\n",
            "     22       \u001b[36m75.4609\u001b[0m  0.0825\n",
            "     23       \u001b[36m68.8648\u001b[0m  0.0593\n",
            "     24       \u001b[36m63.0864\u001b[0m  0.0264\n",
            "     25       \u001b[36m59.5352\u001b[0m  0.0579\n",
            "     26       \u001b[36m55.2921\u001b[0m  0.0350\n",
            "     27       \u001b[36m52.0187\u001b[0m  0.0344\n",
            "     28       \u001b[36m49.7170\u001b[0m  0.0383\n",
            "     29       \u001b[36m48.5070\u001b[0m  0.1028\n",
            "     30       \u001b[36m44.6575\u001b[0m  0.0289\n",
            "     31       \u001b[36m42.9519\u001b[0m  0.0294\n",
            "     32       \u001b[36m40.8607\u001b[0m  0.0592\n",
            "     33       \u001b[36m39.0369\u001b[0m  0.0368\n",
            "     34       \u001b[36m37.1469\u001b[0m  0.0460\n",
            "     35       \u001b[36m36.4820\u001b[0m  0.0469\n",
            "     36       36.7244  0.0555\n",
            "     37       \u001b[36m33.9787\u001b[0m  0.0495\n",
            "     38       34.4752  0.0410\n",
            "     39       \u001b[36m31.3379\u001b[0m  0.0531\n",
            "     40       \u001b[36m27.9352\u001b[0m  0.0675\n",
            "     41       \u001b[36m27.0312\u001b[0m  0.0549\n",
            "     42       \u001b[36m26.5442\u001b[0m  0.0519\n",
            "     43       26.6739  0.0537\n",
            "     44       \u001b[36m24.3630\u001b[0m  0.0506\n",
            "     45       \u001b[36m22.6682\u001b[0m  0.0472\n",
            "     46       24.6463  0.0304\n",
            "     47       \u001b[36m21.7105\u001b[0m  0.0525\n",
            "     48       22.0742  0.0410\n",
            "     49       \u001b[36m18.5863\u001b[0m  0.0480\n",
            "     50       19.3007  0.0446\n",
            "     51       \u001b[36m18.2939\u001b[0m  0.0534\n",
            "     52       \u001b[36m16.9836\u001b[0m  0.0410\n",
            "     53       \u001b[36m15.3917\u001b[0m  0.0291\n",
            "     54       16.1662  0.0376\n",
            "     55       15.6146  0.0514\n",
            "     56       \u001b[36m15.0659\u001b[0m  0.0437\n",
            "     57       \u001b[36m14.3611\u001b[0m  0.0351\n",
            "     58       \u001b[36m12.5465\u001b[0m  0.0358\n",
            "     59       13.8066  0.0281\n",
            "     60       13.4718  0.0349\n",
            "     61       12.5995  0.0406\n",
            "     62       \u001b[36m11.5120\u001b[0m  0.0408\n",
            "     63       11.8215  0.0585\n",
            "     64       11.8613  0.0533\n",
            "     65       \u001b[36m11.2115\u001b[0m  0.0309\n",
            "     66        \u001b[36m9.8911\u001b[0m  0.0406\n",
            "     67       13.3433  0.0419\n",
            "     68        \u001b[36m8.3783\u001b[0m  0.0520\n",
            "     69       12.0853  0.0409\n",
            "     70        8.4857  0.0297\n",
            "     71       13.9247  0.0417\n",
            "     72       13.6398  0.0374\n",
            "     73       10.1204  0.0374\n",
            "     74       10.5871  0.0391\n",
            "     75       13.1607  0.0477\n",
            "     76       10.0209  0.0356\n",
            "     77        8.6908  0.0538\n",
            "     78       10.2739  0.0446\n",
            "     79        \u001b[36m7.3034\u001b[0m  0.0483\n",
            "     80       11.1049  0.0476\n",
            "     81        9.2300  0.0373\n",
            "     82       11.4790  0.0605\n",
            "     83        \u001b[36m6.2630\u001b[0m  0.0423\n",
            "     84        7.1853  0.0331\n",
            "     85        \u001b[36m6.0760\u001b[0m  0.0390\n",
            "     86        \u001b[36m5.6092\u001b[0m  0.0723\n",
            "     87        \u001b[36m4.8132\u001b[0m  0.0627\n",
            "     88       10.1913  0.0792\n",
            "     89        5.3493  0.0559\n",
            "     90        5.7864  0.0611\n",
            "     91        5.4731  0.0549\n",
            "     92        5.0520  0.0327\n",
            "     93        5.2245  0.0384\n",
            "     94        5.0521  0.0395\n",
            "     95        5.9517  0.0484\n",
            "     96        4.9862  0.0397\n",
            "     97        \u001b[36m3.5389\u001b[0m  0.0640\n",
            "     98        4.5678  0.0517\n",
            "     99        6.7433  0.0424\n",
            "    100        4.0865  0.0488\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m83491.4043\u001b[0m  0.0505\n",
            "      2    \u001b[36m66820.8970\u001b[0m  0.0613\n",
            "      3    \u001b[36m53129.8959\u001b[0m  0.0498\n",
            "      4    \u001b[36m41822.3648\u001b[0m  0.0445\n",
            "      5    \u001b[36m32429.8744\u001b[0m  0.0378\n",
            "      6    \u001b[36m24592.7030\u001b[0m  0.0513\n",
            "      7    \u001b[36m18007.4063\u001b[0m  0.0578\n",
            "      8    \u001b[36m12401.3567\u001b[0m  0.0523\n",
            "      9     \u001b[36m7515.3940\u001b[0m  0.0664\n",
            "     10     \u001b[36m3090.7752\u001b[0m  0.0621\n",
            "     11      \u001b[36m213.3169\u001b[0m  0.0350\n",
            "     12       \u001b[36m73.2504\u001b[0m  0.0420\n",
            "     13       \u001b[36m60.8781\u001b[0m  0.0452\n",
            "     14       \u001b[36m56.7500\u001b[0m  0.0432\n",
            "     15       \u001b[36m52.0342\u001b[0m  0.0617\n",
            "     16       \u001b[36m46.2057\u001b[0m  0.0332\n",
            "     17       \u001b[36m45.0974\u001b[0m  0.0413\n",
            "     18       \u001b[36m39.7227\u001b[0m  0.0384\n",
            "     19       \u001b[36m31.3553\u001b[0m  0.0422\n",
            "     20       \u001b[36m28.3578\u001b[0m  0.0392\n",
            "     21       \u001b[36m24.5220\u001b[0m  0.0387\n",
            "     22       \u001b[36m21.7848\u001b[0m  0.0396\n",
            "     23       \u001b[36m19.6845\u001b[0m  0.0437\n",
            "     24       \u001b[36m18.6121\u001b[0m  0.0275\n",
            "     25       \u001b[36m17.8321\u001b[0m  0.0417\n",
            "     26       \u001b[36m16.0222\u001b[0m  0.0451\n",
            "     27       \u001b[36m14.8752\u001b[0m  0.0460\n",
            "     28       \u001b[36m14.8114\u001b[0m  0.0567\n",
            "     29       15.9981  0.0530\n",
            "     30       \u001b[36m11.5795\u001b[0m  0.0515\n",
            "     31       12.2706  0.0451\n",
            "     32       \u001b[36m10.6962\u001b[0m  0.0403\n",
            "     33        \u001b[36m8.6344\u001b[0m  0.0520\n",
            "     34        \u001b[36m8.6319\u001b[0m  0.0450\n",
            "     35        8.9750  0.0404\n",
            "     36        9.4860  0.0402\n",
            "     37        \u001b[36m8.6260\u001b[0m  0.0339\n",
            "     38        \u001b[36m7.9261\u001b[0m  0.0412\n",
            "     39        \u001b[36m6.5131\u001b[0m  0.0362\n",
            "     40        \u001b[36m4.8006\u001b[0m  0.0403\n",
            "     41        6.1876  0.0524\n",
            "     42        7.9606  0.0496\n",
            "     43        6.1526  0.0485\n",
            "     44        5.5354  0.0662\n",
            "     45        \u001b[36m4.0432\u001b[0m  0.0515\n",
            "     46        5.6674  0.0487\n",
            "     47        \u001b[36m3.8844\u001b[0m  0.0411\n",
            "     48        4.6921  0.0513\n",
            "     49        4.1480  0.0522\n",
            "     50        \u001b[36m2.9506\u001b[0m  0.0438\n",
            "     51        6.1581  0.0385\n",
            "     52        3.5294  0.0547\n",
            "     53        4.3230  0.0582\n",
            "     54        3.5632  0.0598\n",
            "     55        7.8666  0.0400\n",
            "     56        8.3101  0.0477\n",
            "     57        4.2139  0.0425\n",
            "     58        4.2891  0.0487\n",
            "     59        6.0792  0.0390\n",
            "     60        8.2393  0.0936\n",
            "     61       10.5913  0.0587\n",
            "     62        4.8841  0.0531\n",
            "     63        6.8641  0.0424\n",
            "     64        \u001b[36m1.9182\u001b[0m  0.0542\n",
            "     65        4.8602  0.0472\n",
            "     66        3.8290  0.0594\n",
            "     67        4.5675  0.0477\n",
            "     68        3.0709  0.0486\n",
            "     69        4.0184  0.0576\n",
            "     70        2.9667  0.0553\n",
            "     71        5.9286  0.0432\n",
            "     72        2.7267  0.0539\n",
            "     73        2.2514  0.0512\n",
            "     74        5.7740  0.0440\n",
            "     75        3.9968  0.0610\n",
            "     76        3.6171  0.0511\n",
            "     77        5.6954  0.0503\n",
            "     78        2.5511  0.0552\n",
            "     79        4.1835  0.0327\n",
            "     80       18.9488  0.0435\n",
            "     81       11.6903  0.0482\n",
            "     82        6.2449  0.0488\n",
            "     83        2.1071  0.0434\n",
            "     84        4.3945  0.0501\n",
            "     85       10.2493  0.0397\n",
            "     86        8.9220  0.0431\n",
            "     87        4.3098  0.0459\n",
            "     88        8.8389  0.0493\n",
            "     89        2.9199  0.0389\n",
            "     90        2.6503  0.0369\n",
            "     91        3.3250  0.0448\n",
            "     92        4.2169  0.0404\n",
            "     93        7.7112  0.0372\n",
            "     94        2.5762  0.0367\n",
            "     95        3.4889  0.0411\n",
            "     96        9.0206  0.0463\n",
            "     97        2.6268  0.0564\n",
            "     98        4.3793  0.0326\n",
            "     99        3.0004  0.0412\n",
            "    100        9.7866  0.0403\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m83971.7216\u001b[0m  0.0382\n",
            "      2    \u001b[36m66818.5103\u001b[0m  0.0455\n",
            "      3    \u001b[36m53012.2095\u001b[0m  0.0462\n",
            "      4    \u001b[36m41871.3822\u001b[0m  0.0435\n",
            "      5    \u001b[36m32827.5082\u001b[0m  0.0336\n",
            "      6    \u001b[36m25433.7573\u001b[0m  0.0390\n",
            "      7    \u001b[36m19357.0905\u001b[0m  0.0628\n",
            "      8    \u001b[36m14337.3561\u001b[0m  0.0436\n",
            "      9    \u001b[36m10116.6218\u001b[0m  0.0407\n",
            "     10     \u001b[36m6419.9638\u001b[0m  0.0384\n",
            "     11     \u001b[36m3025.9584\u001b[0m  0.0568\n",
            "     12      \u001b[36m433.4614\u001b[0m  0.0315\n",
            "     13      \u001b[36m195.8986\u001b[0m  0.0360\n",
            "     14      \u001b[36m173.1129\u001b[0m  0.0382\n",
            "     15      \u001b[36m152.7550\u001b[0m  0.0434\n",
            "     16      \u001b[36m133.0741\u001b[0m  0.0459\n",
            "     17      \u001b[36m112.8533\u001b[0m  0.0609\n",
            "     18       \u001b[36m93.2339\u001b[0m  0.0517\n",
            "     19       \u001b[36m74.0185\u001b[0m  0.0416\n",
            "     20       \u001b[36m56.1536\u001b[0m  0.0449\n",
            "     21       \u001b[36m49.2686\u001b[0m  0.0464\n",
            "     22       \u001b[36m34.6397\u001b[0m  0.0512\n",
            "     23       \u001b[36m32.1240\u001b[0m  0.0472\n",
            "     24       \u001b[36m30.4674\u001b[0m  0.0394\n",
            "     25       \u001b[36m29.0919\u001b[0m  0.0473\n",
            "     26       \u001b[36m27.2387\u001b[0m  0.0549\n",
            "     27       \u001b[36m26.3115\u001b[0m  0.0468\n",
            "     28       \u001b[36m25.6035\u001b[0m  0.0461\n",
            "     29       \u001b[36m25.1595\u001b[0m  0.0409\n",
            "     30       \u001b[36m23.4870\u001b[0m  0.0452\n",
            "     31       \u001b[36m22.3291\u001b[0m  0.0451\n",
            "     32       \u001b[36m22.2358\u001b[0m  0.0430\n",
            "     33       \u001b[36m21.7426\u001b[0m  0.0390\n",
            "     34       \u001b[36m19.6614\u001b[0m  0.0484\n",
            "     35       \u001b[36m19.6331\u001b[0m  0.0299\n",
            "     36       \u001b[36m18.1691\u001b[0m  0.0393\n",
            "     37       18.5818  0.0567\n",
            "     38       \u001b[36m16.7979\u001b[0m  0.0401\n",
            "     39       \u001b[36m16.5145\u001b[0m  0.0462\n",
            "     40       17.0122  0.0382\n",
            "     41       16.6356  0.0480\n",
            "     42       \u001b[36m14.4565\u001b[0m  0.0428\n",
            "     43       16.9318  0.0383\n",
            "     44       16.2050  0.0370\n",
            "     45       \u001b[36m13.9821\u001b[0m  0.0376\n",
            "     46       15.3341  0.0345\n",
            "     47       \u001b[36m13.9521\u001b[0m  0.0433\n",
            "     48       14.5964  0.0423\n",
            "     49       \u001b[36m12.0108\u001b[0m  0.0380\n",
            "     50        \u001b[36m9.9068\u001b[0m  0.0301\n",
            "     51       11.3835  0.0356\n",
            "     52        \u001b[36m8.8688\u001b[0m  0.0415\n",
            "     53       11.5385  0.0373\n",
            "     54       10.7614  0.0318\n",
            "     55        9.7611  0.0382\n",
            "     56        \u001b[36m8.0933\u001b[0m  0.0440\n",
            "     57        9.4942  0.0472\n",
            "     58        \u001b[36m8.0531\u001b[0m  0.0426\n",
            "     59        \u001b[36m7.7674\u001b[0m  0.0367\n",
            "     60        \u001b[36m6.3005\u001b[0m  0.0498\n",
            "     61        9.0454  0.0461\n",
            "     62        7.5232  0.0459\n",
            "     63        6.9778  0.0411\n",
            "     64        8.7610  0.0385\n",
            "     65        \u001b[36m5.3877\u001b[0m  0.0419\n",
            "     66        9.0234  0.0352\n",
            "     67        7.0411  0.0482\n",
            "     68        8.0118  0.0373\n",
            "     69        7.8213  0.0416\n",
            "     70        5.8696  0.0373\n",
            "     71        7.5419  0.0526\n",
            "     72        6.2770  0.0320\n",
            "     73        6.4720  0.0465\n",
            "     74        6.3470  0.0467\n",
            "     75        5.9057  0.0433\n",
            "     76        \u001b[36m3.4935\u001b[0m  0.0444\n",
            "     77        3.5942  0.0389\n",
            "     78        3.9903  0.0345\n",
            "     79        \u001b[36m3.3586\u001b[0m  0.0556\n",
            "     80        4.0192  0.0411\n",
            "     81        \u001b[36m3.2175\u001b[0m  0.0344\n",
            "     82        \u001b[36m3.1683\u001b[0m  0.0439\n",
            "     83        8.1243  0.0448\n",
            "     84        6.3991  0.0335\n",
            "     85        7.9937  0.0372\n",
            "     86        6.7199  0.0340\n",
            "     87        4.7148  0.0403\n",
            "     88        4.2474  0.0388\n",
            "     89        8.4175  0.0484\n",
            "     90        9.8225  0.0382\n",
            "     91       22.9772  0.0432\n",
            "     92        4.7252  0.0544\n",
            "     93        4.7498  0.0478\n",
            "     94        9.5381  0.0400\n",
            "     95       18.4285  0.0447\n",
            "     96        4.9564  0.0462\n",
            "     97        4.1719  0.0335\n",
            "     98        5.1125  0.0434\n",
            "     99        4.6824  0.0426\n",
            "    100        6.6065  0.0637\n"
          ]
        }
      ],
      "source": [
        "resultados = cross_val_score(classificador_sklearn, previsores, classe, cv = 10, scoring = 'accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4o5859fKM1q",
        "outputId": "b1d41ccb-1a97-48d6-91e2-21b656e68fae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "resultados.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2tLKmkuKQsM",
        "outputId": "870c7e24-1221-4697-8bf2-a0440ad245e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.77192982, 0.84210526, 0.80701754, 0.92982456, 0.89473684,\n",
              "       0.89473684, 0.80701754, 0.8245614 , 0.85964912, 0.78571429])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZpQL5q0KZ-Q",
        "outputId": "1d11bd15-7e2e-4574-cfb1-feb057dc80e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8417293233082708"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "media = resultados.mean()\n",
        "media"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZqSmfaCKjb0",
        "outputId": "8565ad0f-9c61-43ab-dbf1-729111c7a02c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.04941237984060323"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "desvio = resultados.std()\n",
        "desvio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "previsores_treinamento = pd.read_csv('./content/entradas-breast.csv')\n",
        "classe_treinamento = pd.read_csv('./content/saidas-breast.csv')\n",
        "\n",
        "previsores_teste = torch.tensor(np.array(previsores_treinamento), dtype=torch.float)\n",
        "previsoes = classificador_sklearn.forward(previsores_teste)\n",
        "classe_treinamento = np.array(classe_treinamento)\n",
        "\n",
        "taxa_acerto = accuracy_score(classe, previsores)\n",
        "matriz = confusion_matrix(classe, previsores)\n",
        "sns.heatmap(matriz, annot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMDGyU0RltXV"
      },
      "source": [
        "## Etapa 6: Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "OU8LnHmFLyFV"
      },
      "outputs": [],
      "source": [
        "class classificador_torch(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # 30 -> 16 -> 16 -> 1\n",
        "    self.dense0 = nn.Linear(30, 16)\n",
        "    torch.nn.init.uniform_(self.dense0.weight)\n",
        "    self.activation0 = nn.ReLU()\n",
        "    self.dropout0 = nn.Dropout(0.2)\n",
        "    self.dense1 = nn.Linear(16, 16)\n",
        "    torch.nn.init.uniform_(self.dense1.weight)\n",
        "    self.activation1 = nn.ReLU()\n",
        "    self.dropout1 = nn.Dropout(0.2)\n",
        "    self.dense2 = nn.Linear(16, 1)\n",
        "    torch.nn.init.uniform_(self.dense2.weight)\n",
        "    # self.output = nn.Sigmoid() ** ATUALIZAÇÃO **\n",
        "\n",
        "  def forward(self, X):\n",
        "    X = self.dense0(X)\n",
        "    X = self.activation0(X)\n",
        "    X = self.dropout0(X)\n",
        "    X = self.dense1(X)\n",
        "    X = self.activation1(X)\n",
        "    X = self.dropout1(X)\n",
        "    X = self.dense2(X)\n",
        "    # X = self.output(X) ** ATUALIZAÇÃO **\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1ksRGpRyMZwi"
      },
      "outputs": [],
      "source": [
        "classificador_sklearn = NeuralNetBinaryClassifier(module=classificador_torch,\n",
        "                                                  criterion=torch.nn.BCEWithLogitsLoss, # ** ATUALIZAÇÃO **\n",
        "                                                  optimizer=torch.optim.Adam,\n",
        "                                                  lr=0.001,\n",
        "                                                  optimizer__weight_decay=0.0001,\n",
        "                                                  max_epochs=100,\n",
        "                                                  batch_size=10,\n",
        "                                                  train_split=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKOttNqOMflW",
        "outputId": "b2a070a0-a612-4273-ab66-2ff651b62f87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m76826.3905\u001b[0m  0.1111\n",
            "      2    \u001b[36m60939.8401\u001b[0m  0.1907\n",
            "      3    \u001b[36m48414.3242\u001b[0m  0.1010\n",
            "      4    \u001b[36m36653.4906\u001b[0m  0.1085\n",
            "      5    \u001b[36m28374.9964\u001b[0m  0.1156\n",
            "      6    \u001b[36m21817.0954\u001b[0m  0.0914\n",
            "      7    \u001b[36m16252.4788\u001b[0m  0.0814\n",
            "      8    \u001b[36m11266.8543\u001b[0m  0.1139\n",
            "      9     \u001b[36m7430.2927\u001b[0m  0.1182\n",
            "     10     \u001b[36m4148.7757\u001b[0m  0.1047\n",
            "     11     \u001b[36m2851.8518\u001b[0m  0.1064\n",
            "     12     \u001b[36m2349.3622\u001b[0m  0.1198\n",
            "     13     2574.3610  0.1198\n",
            "     14     \u001b[36m2280.8971\u001b[0m  0.1159\n",
            "     15     \u001b[36m1909.6447\u001b[0m  0.1136\n",
            "     16     \u001b[36m1792.1108\u001b[0m  0.1002\n",
            "     17     \u001b[36m1636.7896\u001b[0m  0.0977\n",
            "     18     \u001b[36m1475.0404\u001b[0m  0.0892\n",
            "     19     1628.6917  0.0943\n",
            "     20     1758.2283  0.1070\n",
            "     21     1512.2893  0.1186\n",
            "     22     \u001b[36m1185.2862\u001b[0m  0.0921\n",
            "     23     \u001b[36m1009.3946\u001b[0m  0.1067\n",
            "     24     1060.6700  0.0581\n",
            "     25     1212.9749  0.0659\n",
            "     26      \u001b[36m966.5793\u001b[0m  0.0771\n",
            "     27      \u001b[36m882.4840\u001b[0m  0.0813\n",
            "     28      \u001b[36m844.1325\u001b[0m  0.0708\n",
            "     29      \u001b[36m831.6529\u001b[0m  0.0970\n",
            "     30      \u001b[36m682.6983\u001b[0m  0.0862\n",
            "     31      725.7149  0.0719\n",
            "     32      704.2438  0.0581\n",
            "     33      \u001b[36m607.3053\u001b[0m  0.0631\n",
            "     34      656.2613  0.0681\n",
            "     35      \u001b[36m537.6641\u001b[0m  0.0841\n",
            "     36      \u001b[36m514.6392\u001b[0m  0.0644\n",
            "     37      \u001b[36m471.6017\u001b[0m  0.0552\n",
            "     38      \u001b[36m405.4937\u001b[0m  0.0720\n",
            "     39      473.5351  0.0630\n",
            "     40      444.7149  0.0489\n",
            "     41      \u001b[36m389.4163\u001b[0m  0.0933\n",
            "     42      \u001b[36m330.1009\u001b[0m  0.0602\n",
            "     43      333.7783  0.0750\n",
            "     44      335.4325  0.0656\n",
            "     45      \u001b[36m327.4832\u001b[0m  0.0681\n",
            "     46      \u001b[36m243.1141\u001b[0m  0.0693\n",
            "     47      \u001b[36m231.8815\u001b[0m  0.0947\n",
            "     48      232.9112  0.0556\n",
            "     49      \u001b[36m228.6587\u001b[0m  0.0936\n",
            "     50      \u001b[36m183.2917\u001b[0m  0.1130\n",
            "     51      196.7406  0.0878\n",
            "     52      184.0080  0.0915\n",
            "     53      185.6888  0.0704\n",
            "     54      \u001b[36m158.0059\u001b[0m  0.0577\n",
            "     55      160.0562  0.0599\n",
            "     56      \u001b[36m123.8344\u001b[0m  0.0744\n",
            "     57      138.5747  0.0683\n",
            "     58      132.7484  0.0830\n",
            "     59      128.3446  0.0660\n",
            "     60      \u001b[36m101.8032\u001b[0m  0.0780\n",
            "     61       \u001b[36m94.2890\u001b[0m  0.0518\n",
            "     62       \u001b[36m90.2274\u001b[0m  0.0783\n",
            "     63       99.8098  0.0549\n",
            "     64       95.0994  0.0637\n",
            "     65       \u001b[36m88.6559\u001b[0m  0.0941\n",
            "     66       \u001b[36m79.7201\u001b[0m  0.0796\n",
            "     67       \u001b[36m78.0844\u001b[0m  0.0515\n",
            "     68       \u001b[36m67.5350\u001b[0m  0.0670\n",
            "     69       \u001b[36m59.5162\u001b[0m  0.0695\n",
            "     70       68.6458  0.0476\n",
            "     71       \u001b[36m55.9799\u001b[0m  0.0842\n",
            "     72       58.2017  0.0551\n",
            "     73       \u001b[36m54.1799\u001b[0m  0.0598\n",
            "     74       \u001b[36m47.2064\u001b[0m  0.0607\n",
            "     75       \u001b[36m43.4593\u001b[0m  0.0628\n",
            "     76       44.2701  0.0630\n",
            "     77       \u001b[36m39.7895\u001b[0m  0.0599\n",
            "     78       \u001b[36m39.2675\u001b[0m  0.0843\n",
            "     79       \u001b[36m34.3105\u001b[0m  0.0765\n",
            "     80       \u001b[36m31.9721\u001b[0m  0.0791\n",
            "     81       \u001b[36m28.4781\u001b[0m  0.1230\n",
            "     82       \u001b[36m27.5056\u001b[0m  0.0543\n",
            "     83       \u001b[36m26.7729\u001b[0m  0.0559\n",
            "     84       \u001b[36m23.7685\u001b[0m  0.0910\n",
            "     85       \u001b[36m21.5610\u001b[0m  0.0594\n",
            "     86       \u001b[36m16.5939\u001b[0m  0.0545\n",
            "     87       20.5169  0.0626\n",
            "     88       17.6164  0.0659\n",
            "     89       \u001b[36m15.9072\u001b[0m  0.0825\n",
            "     90       \u001b[36m15.5688\u001b[0m  0.0815\n",
            "     91       \u001b[36m12.9836\u001b[0m  0.0590\n",
            "     92       13.2616  0.0528\n",
            "     93       \u001b[36m10.5046\u001b[0m  0.0577\n",
            "     94       10.8232  0.0937\n",
            "     95       13.6815  0.0556\n",
            "     96        \u001b[36m9.3214\u001b[0m  0.0803\n",
            "     97        9.5281  0.0953\n",
            "     98        \u001b[36m7.2867\u001b[0m  0.0649\n",
            "     99        8.7358  0.0519\n",
            "    100        8.2652  0.0584\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m94331.8626\u001b[0m  0.0586\n",
            "      2    \u001b[36m73836.3185\u001b[0m  0.0746\n",
            "      3    \u001b[36m58569.9038\u001b[0m  0.0944\n",
            "      4    \u001b[36m46511.7651\u001b[0m  0.0699\n",
            "      5    \u001b[36m36482.9981\u001b[0m  0.0661\n",
            "      6    \u001b[36m28545.8674\u001b[0m  0.0782\n",
            "      7    \u001b[36m22721.0112\u001b[0m  0.0951\n",
            "      8    \u001b[36m17263.8317\u001b[0m  0.0806\n",
            "      9    \u001b[36m12934.7222\u001b[0m  0.0544\n",
            "     10     \u001b[36m9753.7839\u001b[0m  0.0793\n",
            "     11     \u001b[36m6454.7807\u001b[0m  0.0598\n",
            "     12     \u001b[36m3954.6400\u001b[0m  0.0916\n",
            "     13     \u001b[36m1840.2159\u001b[0m  0.0635\n",
            "     14     \u001b[36m1302.3103\u001b[0m  0.0541\n",
            "     15     1347.8051  0.0540\n",
            "     16     \u001b[36m1055.0016\u001b[0m  0.1188\n",
            "     17     1074.8523  0.0768\n",
            "     18     1121.7135  0.0525\n",
            "     19      \u001b[36m855.2372\u001b[0m  0.0789\n",
            "     20      \u001b[36m821.9548\u001b[0m  0.0713\n",
            "     21      832.3240  0.0825\n",
            "     22      \u001b[36m821.5972\u001b[0m  0.0756\n",
            "     23      \u001b[36m803.9953\u001b[0m  0.0666\n",
            "     24      \u001b[36m711.3670\u001b[0m  0.0845\n",
            "     25      \u001b[36m607.2903\u001b[0m  0.0597\n",
            "     26      641.9345  0.0818\n",
            "     27      \u001b[36m545.9051\u001b[0m  0.0743\n",
            "     28      581.2045  0.0613\n",
            "     29      \u001b[36m472.7621\u001b[0m  0.0531\n",
            "     30      501.3295  0.0580\n",
            "     31      \u001b[36m468.0686\u001b[0m  0.0560\n",
            "     32      \u001b[36m448.7314\u001b[0m  0.0663\n",
            "     33      \u001b[36m399.4633\u001b[0m  0.0712\n",
            "     34      \u001b[36m391.5458\u001b[0m  0.0917\n",
            "     35      403.9615  0.0627\n",
            "     36      \u001b[36m330.4243\u001b[0m  0.0622\n",
            "     37      369.1813  0.0556\n",
            "     38      \u001b[36m310.0491\u001b[0m  0.0809\n",
            "     39      324.5775  0.1491\n",
            "     40      \u001b[36m302.6654\u001b[0m  0.0651\n",
            "     41      \u001b[36m267.6292\u001b[0m  0.0727\n",
            "     42      \u001b[36m220.0955\u001b[0m  0.0593\n",
            "     43      255.8362  0.0749\n",
            "     44      \u001b[36m211.1805\u001b[0m  0.0720\n",
            "     45      212.4762  0.0918\n",
            "     46      219.3894  0.0712\n",
            "     47      223.9682  0.0617\n",
            "     48      \u001b[36m205.7507\u001b[0m  0.0845\n",
            "     49      \u001b[36m153.3409\u001b[0m  0.0745\n",
            "     50      \u001b[36m139.5194\u001b[0m  0.0781\n",
            "     51      157.9669  0.0871\n",
            "     52      \u001b[36m125.1382\u001b[0m  0.0736\n",
            "     53      140.2107  0.0500\n",
            "     54      132.7300  0.0795\n",
            "     55      \u001b[36m112.5749\u001b[0m  0.0972\n",
            "     56      \u001b[36m107.8402\u001b[0m  0.0760\n",
            "     57       \u001b[36m99.7016\u001b[0m  0.1036\n",
            "     58      123.7788  0.0657\n",
            "     59       \u001b[36m88.3827\u001b[0m  0.0654\n",
            "     60       \u001b[36m88.3472\u001b[0m  0.0664\n",
            "     61       \u001b[36m70.2247\u001b[0m  0.0600\n",
            "     62       72.8657  0.0890\n",
            "     63       \u001b[36m57.7074\u001b[0m  0.0743\n",
            "     64       69.5677  0.0692\n",
            "     65       67.7496  0.0961\n",
            "     66       \u001b[36m54.6646\u001b[0m  0.0561\n",
            "     67       \u001b[36m54.3666\u001b[0m  0.0622\n",
            "     68       \u001b[36m52.4990\u001b[0m  0.0760\n",
            "     69       \u001b[36m50.7827\u001b[0m  0.0797\n",
            "     70       \u001b[36m46.4242\u001b[0m  0.0658\n",
            "     71       \u001b[36m37.4911\u001b[0m  0.0579\n",
            "     72       \u001b[36m35.7967\u001b[0m  0.0438\n",
            "     73       \u001b[36m35.5466\u001b[0m  0.0937\n",
            "     74       \u001b[36m29.5025\u001b[0m  0.0860\n",
            "     75       29.5847  0.0625\n",
            "     76       30.0614  0.0861\n",
            "     77       \u001b[36m25.9646\u001b[0m  0.0713\n",
            "     78       \u001b[36m15.9950\u001b[0m  0.0645\n",
            "     79       20.1381  0.0547\n",
            "     80       18.9734  0.0697\n",
            "     81       18.3048  0.0700\n",
            "     82       19.5076  0.0605\n",
            "     83       \u001b[36m13.0035\u001b[0m  0.0711\n",
            "     84       \u001b[36m10.9458\u001b[0m  0.0582\n",
            "     85        \u001b[36m7.3856\u001b[0m  0.0721\n",
            "     86        \u001b[36m7.2494\u001b[0m  0.0593\n",
            "     87       11.0610  0.0616\n",
            "     88        7.6653  0.0564\n",
            "     89        \u001b[36m5.5365\u001b[0m  0.0896\n",
            "     90        7.4475  0.0650\n",
            "     91        \u001b[36m4.9506\u001b[0m  0.0576\n",
            "     92        5.4332  0.0840\n",
            "     93        5.3586  0.0735\n",
            "     94        \u001b[36m3.9427\u001b[0m  0.1063\n",
            "     95        5.6242  0.0697\n",
            "     96        7.2980  0.0830\n",
            "     97        4.0016  0.0913\n",
            "     98        6.9869  0.0616\n",
            "     99        7.8392  0.0851\n",
            "    100        3.9875  0.0635\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m87396.8860\u001b[0m  0.0885\n",
            "      2    \u001b[36m72011.5097\u001b[0m  0.0663\n",
            "      3    \u001b[36m56444.4389\u001b[0m  0.0751\n",
            "      4    \u001b[36m42683.6609\u001b[0m  0.0702\n",
            "      5    \u001b[36m31856.5568\u001b[0m  0.0853\n",
            "      6    \u001b[36m23540.8414\u001b[0m  0.0601\n",
            "      7    \u001b[36m16044.0491\u001b[0m  0.0561\n",
            "      8     \u001b[36m9130.3890\u001b[0m  0.0671\n",
            "      9     \u001b[36m4930.9846\u001b[0m  0.0606\n",
            "     10     \u001b[36m3708.5098\u001b[0m  0.0913\n",
            "     11     \u001b[36m2794.7396\u001b[0m  0.0606\n",
            "     12     \u001b[36m2649.5201\u001b[0m  0.1262\n",
            "     13     3078.5390  0.0665\n",
            "     14     \u001b[36m2522.1272\u001b[0m  0.0497\n",
            "     15     3069.8651  0.0914\n",
            "     16     2617.5100  0.0966\n",
            "     17     \u001b[36m2427.4671\u001b[0m  0.0654\n",
            "     18     2447.7333  0.0692\n",
            "     19     \u001b[36m2414.7248\u001b[0m  0.0636\n",
            "     20     \u001b[36m2170.7687\u001b[0m  0.0715\n",
            "     21     \u001b[36m1793.8881\u001b[0m  0.0894\n",
            "     22     \u001b[36m1518.5655\u001b[0m  0.0499\n",
            "     23     1780.3139  0.0637\n",
            "     24     1820.3182  0.0677\n",
            "     25     1553.8183  0.0667\n",
            "     26     \u001b[36m1370.5373\u001b[0m  0.0513\n",
            "     27     1504.7377  0.0686\n",
            "     28     \u001b[36m1176.1967\u001b[0m  0.0889\n",
            "     29     \u001b[36m1175.7196\u001b[0m  0.0667\n",
            "     30     \u001b[36m1106.6567\u001b[0m  0.0839\n",
            "     31     \u001b[36m1098.5197\u001b[0m  0.0714\n",
            "     32     \u001b[36m1020.4519\u001b[0m  0.0584\n",
            "     33      \u001b[36m867.2467\u001b[0m  0.0721\n",
            "     34      971.4057  0.0742\n",
            "     35      874.7849  0.0841\n",
            "     36      \u001b[36m743.3582\u001b[0m  0.0551\n",
            "     37      769.2679  0.0679\n",
            "     38      850.1898  0.0759\n",
            "     39      \u001b[36m707.9417\u001b[0m  0.0482\n",
            "     40      \u001b[36m530.4154\u001b[0m  0.0609\n",
            "     41      728.2530  0.0742\n",
            "     42      535.5683  0.0861\n",
            "     43      \u001b[36m504.6815\u001b[0m  0.0704\n",
            "     44      \u001b[36m450.4975\u001b[0m  0.0519\n",
            "     45      \u001b[36m424.7038\u001b[0m  0.0832\n",
            "     46      \u001b[36m405.5754\u001b[0m  0.0843\n",
            "     47      416.9424  0.0925\n",
            "     48      \u001b[36m347.8843\u001b[0m  0.0779\n",
            "     49      \u001b[36m326.0410\u001b[0m  0.0620\n",
            "     50      \u001b[36m295.2752\u001b[0m  0.0846\n",
            "     51      341.2894  0.0647\n",
            "     52      301.8203  0.0743\n",
            "     53      \u001b[36m255.9870\u001b[0m  0.0628\n",
            "     54      295.8615  0.0596\n",
            "     55      271.1260  0.0672\n",
            "     56      \u001b[36m242.7194\u001b[0m  0.0770\n",
            "     57      267.4918  0.0708\n",
            "     58      \u001b[36m211.3134\u001b[0m  0.0766\n",
            "     59      \u001b[36m210.2481\u001b[0m  0.0609\n",
            "     60      \u001b[36m197.4521\u001b[0m  0.0729\n",
            "     61      \u001b[36m174.4583\u001b[0m  0.0673\n",
            "     62      176.5047  0.0823\n",
            "     63      \u001b[36m136.6871\u001b[0m  0.0905\n",
            "     64      153.6045  0.0629\n",
            "     65      145.5375  0.0757\n",
            "     66      \u001b[36m132.8955\u001b[0m  0.0596\n",
            "     67      141.7328  0.0484\n",
            "     68      142.2594  0.0557\n",
            "     69      \u001b[36m127.4871\u001b[0m  0.0820\n",
            "     70      \u001b[36m118.9979\u001b[0m  0.1000\n",
            "     71      \u001b[36m113.4178\u001b[0m  0.0787\n",
            "     72       \u001b[36m96.4512\u001b[0m  0.0741\n",
            "     73      101.2956  0.1013\n",
            "     74       \u001b[36m91.8217\u001b[0m  0.0876\n",
            "     75       \u001b[36m65.8680\u001b[0m  0.0770\n",
            "     76       85.0079  0.0731\n",
            "     77       67.4391  0.1120\n",
            "     78       67.3140  0.0569\n",
            "     79       71.9978  0.0889\n",
            "     80       67.4032  0.0625\n",
            "     81       \u001b[36m61.1544\u001b[0m  0.0691\n",
            "     82       \u001b[36m50.5470\u001b[0m  0.0686\n",
            "     83       62.0023  0.0797\n",
            "     84       52.0142  0.0484\n",
            "     85       \u001b[36m49.8848\u001b[0m  0.0604\n",
            "     86       \u001b[36m48.8805\u001b[0m  0.0807\n",
            "     87       \u001b[36m43.0632\u001b[0m  0.0831\n",
            "     88       \u001b[36m42.4934\u001b[0m  0.0663\n",
            "     89       45.8037  0.0726\n",
            "     90       \u001b[36m33.4369\u001b[0m  0.0504\n",
            "     91       \u001b[36m28.3286\u001b[0m  0.1025\n",
            "     92       31.6729  0.0853\n",
            "     93       \u001b[36m27.8384\u001b[0m  0.0752\n",
            "     94       \u001b[36m23.1280\u001b[0m  0.0862\n",
            "     95       25.9800  0.0740\n",
            "     96       26.8922  0.0967\n",
            "     97       \u001b[36m22.1914\u001b[0m  0.0721\n",
            "     98       \u001b[36m20.0493\u001b[0m  0.0513\n",
            "     99       \u001b[36m19.6807\u001b[0m  0.0899\n",
            "    100       \u001b[36m18.2878\u001b[0m  0.0977\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m86974.9099\u001b[0m  0.0566\n",
            "      2    \u001b[36m68341.4130\u001b[0m  0.0679\n",
            "      3    \u001b[36m53586.9121\u001b[0m  0.0647\n",
            "      4    \u001b[36m42055.8901\u001b[0m  0.0744\n",
            "      5    \u001b[36m33682.1911\u001b[0m  0.1000\n",
            "      6    \u001b[36m26227.9588\u001b[0m  0.0695\n",
            "      7    \u001b[36m18987.6687\u001b[0m  0.0827\n",
            "      8    \u001b[36m13399.9876\u001b[0m  0.0613\n",
            "      9     \u001b[36m8882.8754\u001b[0m  0.0608\n",
            "     10     \u001b[36m4950.2306\u001b[0m  0.0601\n",
            "     11     \u001b[36m3101.5564\u001b[0m  0.0750\n",
            "     12     \u001b[36m2343.0089\u001b[0m  0.0611\n",
            "     13     \u001b[36m2065.0704\u001b[0m  0.0706\n",
            "     14     2421.6045  0.0686\n",
            "     15     2067.1439  0.0988\n",
            "     16     \u001b[36m1794.8131\u001b[0m  0.0620\n",
            "     17     \u001b[36m1759.1874\u001b[0m  0.1005\n",
            "     18     \u001b[36m1692.5877\u001b[0m  0.0673\n",
            "     19     \u001b[36m1624.5949\u001b[0m  0.0703\n",
            "     20     \u001b[36m1484.8450\u001b[0m  0.0859\n",
            "     21     1499.7870  0.0697\n",
            "     22     \u001b[36m1341.7819\u001b[0m  0.0690\n",
            "     23     \u001b[36m1173.9133\u001b[0m  0.1088\n",
            "     24     1470.0261  0.0651\n",
            "     25     1176.2260  0.0589\n",
            "     26     1182.6635  0.0824\n",
            "     27     1229.9756  0.0918\n",
            "     28     \u001b[36m1031.1968\u001b[0m  0.0546\n",
            "     29      \u001b[36m900.9183\u001b[0m  0.0828\n",
            "     30     1016.0546  0.0721\n",
            "     31      \u001b[36m761.0230\u001b[0m  0.0742\n",
            "     32      865.1583  0.0737\n",
            "     33      \u001b[36m713.5998\u001b[0m  0.0661\n",
            "     34      860.6856  0.0885\n",
            "     35      722.5242  0.0616\n",
            "     36      \u001b[36m584.2314\u001b[0m  0.0642\n",
            "     37      609.8804  0.0680\n",
            "     38      600.4790  0.0783\n",
            "     39      644.1940  0.0702\n",
            "     40      \u001b[36m510.9903\u001b[0m  0.0719\n",
            "     41      545.5198  0.0627\n",
            "     42      \u001b[36m461.2578\u001b[0m  0.0673\n",
            "     43      \u001b[36m428.2267\u001b[0m  0.0750\n",
            "     44      455.7431  0.0835\n",
            "     45      494.6797  0.0637\n",
            "     46      \u001b[36m350.8056\u001b[0m  0.0634\n",
            "     47      365.2771  0.0577\n",
            "     48      395.8498  0.1008\n",
            "     49      363.9253  0.0564\n",
            "     50      369.5526  0.0488\n",
            "     51      \u001b[36m317.7413\u001b[0m  0.0777\n",
            "     52      \u001b[36m304.5470\u001b[0m  0.0834\n",
            "     53      \u001b[36m251.9443\u001b[0m  0.0625\n",
            "     54      \u001b[36m222.3824\u001b[0m  0.0935\n",
            "     55      \u001b[36m216.5239\u001b[0m  0.0722\n",
            "     56      237.7477  0.0635\n",
            "     57      236.5004  0.0933\n",
            "     58      \u001b[36m200.7107\u001b[0m  0.1075\n",
            "     59      225.9300  0.0864\n",
            "     60      \u001b[36m182.2064\u001b[0m  0.0779\n",
            "     61      207.8614  0.0688\n",
            "     62      \u001b[36m163.4261\u001b[0m  0.0637\n",
            "     63      177.1588  0.0631\n",
            "     64      \u001b[36m144.8401\u001b[0m  0.0788\n",
            "     65      \u001b[36m132.3640\u001b[0m  0.0747\n",
            "     66      133.1161  0.0644\n",
            "     67      \u001b[36m124.9264\u001b[0m  0.0597\n",
            "     68      \u001b[36m114.5809\u001b[0m  0.0636\n",
            "     69      \u001b[36m110.3500\u001b[0m  0.1090\n",
            "     70       \u001b[36m97.4547\u001b[0m  0.0849\n",
            "     71      106.8364  0.0892\n",
            "     72       \u001b[36m92.0020\u001b[0m  0.0801\n",
            "     73       \u001b[36m87.8494\u001b[0m  0.0939\n",
            "     74       \u001b[36m78.8715\u001b[0m  0.0701\n",
            "     75       82.7529  0.0763\n",
            "     76       \u001b[36m77.4957\u001b[0m  0.0977\n",
            "     77       \u001b[36m65.7830\u001b[0m  0.0832\n",
            "     78       \u001b[36m60.9996\u001b[0m  0.0945\n",
            "     79       \u001b[36m60.1846\u001b[0m  0.1016\n",
            "     80       \u001b[36m58.9456\u001b[0m  0.0861\n",
            "     81       \u001b[36m54.1119\u001b[0m  0.0794\n",
            "     82       \u001b[36m46.9663\u001b[0m  0.1741\n",
            "     83       58.7034  0.1204\n",
            "     84       \u001b[36m42.4387\u001b[0m  0.0905\n",
            "     85       49.6667  0.1038\n",
            "     86       45.0194  0.1475\n",
            "     87       43.5038  0.1239\n",
            "     88       \u001b[36m38.2501\u001b[0m  0.1130\n",
            "     89       \u001b[36m37.1038\u001b[0m  0.1343\n",
            "     90       39.4800  0.1209\n",
            "     91       \u001b[36m33.6258\u001b[0m  0.0830\n",
            "     92       \u001b[36m28.3084\u001b[0m  0.0762\n",
            "     93       30.1806  0.0686\n",
            "     94       \u001b[36m27.3945\u001b[0m  0.0723\n",
            "     95       \u001b[36m22.1866\u001b[0m  0.0648\n",
            "     96       22.5788  0.0900\n",
            "     97       23.6314  0.1090\n",
            "     98       \u001b[36m20.5948\u001b[0m  0.0913\n",
            "     99       \u001b[36m17.2979\u001b[0m  0.0490\n",
            "    100       \u001b[36m14.8252\u001b[0m  0.0709\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m78206.1375\u001b[0m  0.0653\n",
            "      2    \u001b[36m61775.4202\u001b[0m  0.0546\n",
            "      3    \u001b[36m46845.9788\u001b[0m  0.0626\n",
            "      4    \u001b[36m35053.2184\u001b[0m  0.0620\n",
            "      5    \u001b[36m27633.3922\u001b[0m  0.0674\n",
            "      6    \u001b[36m18692.0461\u001b[0m  0.0678\n",
            "      7    \u001b[36m12103.4456\u001b[0m  0.0816\n",
            "      8     \u001b[36m6540.6806\u001b[0m  0.0594\n",
            "      9     \u001b[36m3794.3993\u001b[0m  0.0670\n",
            "     10     \u001b[36m3379.1594\u001b[0m  0.0534\n",
            "     11     \u001b[36m3066.1867\u001b[0m  0.0629\n",
            "     12     \u001b[36m2711.9854\u001b[0m  0.0582\n",
            "     13     3011.6446  0.0728\n",
            "     14     \u001b[36m2603.9340\u001b[0m  0.0557\n",
            "     15     2765.4032  0.0637\n",
            "     16     \u001b[36m2303.5207\u001b[0m  0.0781\n",
            "     17     2353.9007  0.0791\n",
            "     18     \u001b[36m1889.0566\u001b[0m  0.1059\n",
            "     19     \u001b[36m1833.3017\u001b[0m  0.1152\n",
            "     20     1990.4909  0.0901\n",
            "     21     \u001b[36m1739.5570\u001b[0m  0.0691\n",
            "     22     \u001b[36m1439.8657\u001b[0m  0.0746\n",
            "     23     1623.8824  0.0885\n",
            "     24     \u001b[36m1389.1664\u001b[0m  0.1018\n",
            "     25     1414.8774  0.1318\n",
            "     26     \u001b[36m1253.5297\u001b[0m  0.1191\n",
            "     27      \u001b[36m958.7572\u001b[0m  0.1058\n",
            "     28     1181.3160  0.0883\n",
            "     29     1043.0526  0.1791\n",
            "     30     1079.1324  0.1159\n",
            "     31      \u001b[36m913.2513\u001b[0m  0.1112\n",
            "     32      927.8041  0.1130\n",
            "     33      \u001b[36m714.4562\u001b[0m  0.0807\n",
            "     34      833.9490  0.1397\n",
            "     35      \u001b[36m600.9191\u001b[0m  0.1065\n",
            "     36      \u001b[36m563.6486\u001b[0m  0.0692\n",
            "     37      704.0625  0.0893\n",
            "     38      685.3072  0.1308\n",
            "     39      575.9521  0.1105\n",
            "     40      \u001b[36m489.3714\u001b[0m  0.1053\n",
            "     41      497.1364  0.0838\n",
            "     42      510.8500  0.1198\n",
            "     43      \u001b[36m428.2409\u001b[0m  0.0740\n",
            "     44      \u001b[36m408.1599\u001b[0m  0.0766\n",
            "     45      \u001b[36m390.6984\u001b[0m  0.1182\n",
            "     46      \u001b[36m338.4259\u001b[0m  0.0837\n",
            "     47      356.7878  0.1190\n",
            "     48      \u001b[36m311.8554\u001b[0m  0.0899\n",
            "     49      332.2927  0.0971\n",
            "     50      \u001b[36m262.6824\u001b[0m  0.0723\n",
            "     51      \u001b[36m251.6152\u001b[0m  0.0736\n",
            "     52      \u001b[36m241.0489\u001b[0m  0.0887\n",
            "     53      264.2078  0.0821\n",
            "     54      246.9649  0.0925\n",
            "     55      \u001b[36m196.1239\u001b[0m  0.0725\n",
            "     56      218.6433  0.1043\n",
            "     57      213.8866  0.0937\n",
            "     58      \u001b[36m188.8455\u001b[0m  0.0836\n",
            "     59      \u001b[36m162.3250\u001b[0m  0.1002\n",
            "     60      199.7783  0.0740\n",
            "     61      174.5998  0.0806\n",
            "     62      \u001b[36m140.5840\u001b[0m  0.0606\n",
            "     63      161.3639  0.0886\n",
            "     64      \u001b[36m134.3632\u001b[0m  0.1056\n",
            "     65      \u001b[36m117.7115\u001b[0m  0.0775\n",
            "     66      \u001b[36m116.7936\u001b[0m  0.0726\n",
            "     67      \u001b[36m116.5650\u001b[0m  0.0903\n",
            "     68      121.2494  0.0607\n",
            "     69      126.8426  0.0710\n",
            "     70       \u001b[36m98.4620\u001b[0m  0.0937\n",
            "     71       \u001b[36m91.4658\u001b[0m  0.0684\n",
            "     72       97.4792  0.0606\n",
            "     73       \u001b[36m82.1496\u001b[0m  0.0607\n",
            "     74       \u001b[36m75.3063\u001b[0m  0.0519\n",
            "     75       79.5469  0.0798\n",
            "     76       \u001b[36m70.1959\u001b[0m  0.0716\n",
            "     77       \u001b[36m66.9517\u001b[0m  0.0756\n",
            "     78       67.0738  0.0841\n",
            "     79       \u001b[36m54.2182\u001b[0m  0.0962\n",
            "     80       61.5398  0.0672\n",
            "     81       56.6511  0.0897\n",
            "     82       57.2906  0.0727\n",
            "     83       \u001b[36m52.8016\u001b[0m  0.0598\n",
            "     84       \u001b[36m46.2924\u001b[0m  0.0656\n",
            "     85       \u001b[36m45.7809\u001b[0m  0.0710\n",
            "     86       \u001b[36m36.6451\u001b[0m  0.0843\n",
            "     87       44.5503  0.0793\n",
            "     88       \u001b[36m35.8393\u001b[0m  0.0613\n",
            "     89       \u001b[36m33.5276\u001b[0m  0.0644\n",
            "     90       37.2947  0.1021\n",
            "     91       \u001b[36m32.6497\u001b[0m  0.0950\n",
            "     92       32.7847  0.0535\n",
            "     93       \u001b[36m27.0438\u001b[0m  0.0658\n",
            "     94       29.9014  0.0752\n",
            "     95       \u001b[36m26.7098\u001b[0m  0.0751\n",
            "     96       27.9164  0.1019\n",
            "     97       \u001b[36m24.8256\u001b[0m  0.0773\n",
            "     98       25.1478  0.0860\n",
            "     99       \u001b[36m20.3050\u001b[0m  0.0874\n",
            "    100       20.9465  0.0750\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1   \u001b[36m109067.2221\u001b[0m  0.0578\n",
            "      2    \u001b[36m86826.5184\u001b[0m  0.0726\n",
            "      3    \u001b[36m70008.1838\u001b[0m  0.0845\n",
            "      4    \u001b[36m54122.4537\u001b[0m  0.0833\n",
            "      5    \u001b[36m43710.2365\u001b[0m  0.0756\n",
            "      6    \u001b[36m34916.7172\u001b[0m  0.0833\n",
            "      7    \u001b[36m27641.4337\u001b[0m  0.0636\n",
            "      8    \u001b[36m21056.3628\u001b[0m  0.0624\n",
            "      9    \u001b[36m16370.8085\u001b[0m  0.0504\n",
            "     10    \u001b[36m11481.5197\u001b[0m  0.0851\n",
            "     11     \u001b[36m8136.4967\u001b[0m  0.0617\n",
            "     12     \u001b[36m4886.2562\u001b[0m  0.0692\n",
            "     13     \u001b[36m3423.2962\u001b[0m  0.0624\n",
            "     14     \u001b[36m2695.2754\u001b[0m  0.0668\n",
            "     15     \u001b[36m2231.5182\u001b[0m  0.0604\n",
            "     16     \u001b[36m2090.2013\u001b[0m  0.0703\n",
            "     17     2146.4085  0.0924\n",
            "     18     2149.2563  0.1237\n",
            "     19     2352.4633  0.1067\n",
            "     20     \u001b[36m1614.5329\u001b[0m  0.0995\n",
            "     21     1924.2167  0.0655\n",
            "     22     1800.4937  0.0936\n",
            "     23     \u001b[36m1384.2658\u001b[0m  0.0764\n",
            "     24     1629.0206  0.0834\n",
            "     25     1417.8937  0.0864\n",
            "     26     1463.9253  0.0850\n",
            "     27     \u001b[36m1199.3959\u001b[0m  0.0923\n",
            "     28     1282.1272  0.0591\n",
            "     29     1418.0174  0.0779\n",
            "     30     \u001b[36m1033.3802\u001b[0m  0.0743\n",
            "     31      \u001b[36m938.2357\u001b[0m  0.0601\n",
            "     32     1165.5335  0.0698\n",
            "     33      964.8654  0.0759\n",
            "     34      \u001b[36m849.9671\u001b[0m  0.0832\n",
            "     35      898.0817  0.0687\n",
            "     36      974.7000  0.0656\n",
            "     37      \u001b[36m772.7319\u001b[0m  0.0916\n",
            "     38      \u001b[36m747.3663\u001b[0m  0.0651\n",
            "     39      \u001b[36m631.2601\u001b[0m  0.0723\n",
            "     40      648.8277  0.0585\n",
            "     41      641.8895  0.0799\n",
            "     42      \u001b[36m577.2152\u001b[0m  0.1043\n",
            "     43      \u001b[36m458.4135\u001b[0m  0.0928\n",
            "     44      514.7515  0.0614\n",
            "     45      498.5840  0.0909\n",
            "     46      \u001b[36m405.3505\u001b[0m  0.1037\n",
            "     47      484.9136  0.0854\n",
            "     48      480.0059  0.0735\n",
            "     49      418.3419  0.0620\n",
            "     50      \u001b[36m339.7261\u001b[0m  0.0718\n",
            "     51      355.0137  0.0908\n",
            "     52      \u001b[36m320.3142\u001b[0m  0.0657\n",
            "     53      322.0950  0.0709\n",
            "     54      \u001b[36m318.4910\u001b[0m  0.0967\n",
            "     55      \u001b[36m302.0798\u001b[0m  0.0832\n",
            "     56      \u001b[36m257.9984\u001b[0m  0.0745\n",
            "     57      \u001b[36m228.1330\u001b[0m  0.0897\n",
            "     58      261.9444  0.0834\n",
            "     59      259.1539  0.0805\n",
            "     60      \u001b[36m226.7977\u001b[0m  0.1151\n",
            "     61      \u001b[36m181.3079\u001b[0m  0.0835\n",
            "     62      184.8519  0.0736\n",
            "     63      218.5514  0.0836\n",
            "     64      \u001b[36m164.8476\u001b[0m  0.0936\n",
            "     65      \u001b[36m160.7384\u001b[0m  0.0706\n",
            "     66      165.0941  0.0805\n",
            "     67      169.9361  0.0928\n",
            "     68      \u001b[36m145.4503\u001b[0m  0.1009\n",
            "     69      \u001b[36m129.0573\u001b[0m  0.0632\n",
            "     70      142.0931  0.0771\n",
            "     71      \u001b[36m109.0905\u001b[0m  0.0640\n",
            "     72      116.6654  0.1004\n",
            "     73      \u001b[36m107.8666\u001b[0m  0.0667\n",
            "     74       \u001b[36m98.1470\u001b[0m  0.0812\n",
            "     75       \u001b[36m94.7146\u001b[0m  0.0837\n",
            "     76       \u001b[36m75.9290\u001b[0m  0.0843\n",
            "     77       95.3535  0.0820\n",
            "     78       \u001b[36m75.7479\u001b[0m  0.0798\n",
            "     79       \u001b[36m74.5019\u001b[0m  0.0533\n",
            "     80       74.7300  0.0567\n",
            "     81       75.6126  0.0910\n",
            "     82       \u001b[36m59.5183\u001b[0m  0.0675\n",
            "     83       65.8353  0.0880\n",
            "     84       \u001b[36m57.3161\u001b[0m  0.0711\n",
            "     85       \u001b[36m50.3799\u001b[0m  0.0692\n",
            "     86       \u001b[36m49.1879\u001b[0m  0.0579\n",
            "     87       \u001b[36m47.9680\u001b[0m  0.0691\n",
            "     88       \u001b[36m42.3000\u001b[0m  0.0630\n",
            "     89       \u001b[36m41.3417\u001b[0m  0.0776\n",
            "     90       53.0017  0.0948\n",
            "     91       \u001b[36m35.1625\u001b[0m  0.0740\n",
            "     92       39.3194  0.0620\n",
            "     93       41.1125  0.0756\n",
            "     94       35.7460  0.0562\n",
            "     95       39.9449  0.0724\n",
            "     96       \u001b[36m30.4300\u001b[0m  0.0871\n",
            "     97       \u001b[36m30.1719\u001b[0m  0.0858\n",
            "     98       34.3248  0.0936\n",
            "     99       \u001b[36m26.5697\u001b[0m  0.0880\n",
            "    100       30.7528  0.0824\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m85683.9431\u001b[0m  0.0806\n",
            "      2    \u001b[36m67056.8542\u001b[0m  0.0630\n",
            "      3    \u001b[36m54557.4711\u001b[0m  0.1063\n",
            "      4    \u001b[36m44003.4218\u001b[0m  0.0742\n",
            "      5    \u001b[36m33732.7965\u001b[0m  0.0877\n",
            "      6    \u001b[36m27104.0860\u001b[0m  0.0824\n",
            "      7    \u001b[36m20246.9434\u001b[0m  0.0717\n",
            "      8    \u001b[36m15704.4229\u001b[0m  0.0597\n",
            "      9    \u001b[36m12833.0946\u001b[0m  0.0827\n",
            "     10     \u001b[36m9322.6485\u001b[0m  0.0697\n",
            "     11     \u001b[36m7008.8917\u001b[0m  0.0725\n",
            "     12     \u001b[36m4863.1730\u001b[0m  0.0739\n",
            "     13     \u001b[36m2895.1872\u001b[0m  0.0733\n",
            "     14     \u001b[36m1822.1073\u001b[0m  0.0871\n",
            "     15     \u001b[36m1201.5306\u001b[0m  0.0810\n",
            "     16     1368.9673  0.0850\n",
            "     17      \u001b[36m997.8408\u001b[0m  0.0711\n",
            "     18     1023.6721  0.0726\n",
            "     19     1095.8294  0.0987\n",
            "     20      \u001b[36m872.4120\u001b[0m  0.0683\n",
            "     21      \u001b[36m767.6456\u001b[0m  0.0838\n",
            "     22      \u001b[36m712.3056\u001b[0m  0.0740\n",
            "     23      719.5810  0.0825\n",
            "     24      \u001b[36m588.5734\u001b[0m  0.1074\n",
            "     25      675.5318  0.1042\n",
            "     26      590.4753  0.0749\n",
            "     27      \u001b[36m564.9313\u001b[0m  0.0722\n",
            "     28      639.2515  0.0620\n",
            "     29      \u001b[36m460.8167\u001b[0m  0.0694\n",
            "     30      548.0205  0.0732\n",
            "     31      484.5846  0.0590\n",
            "     32      \u001b[36m375.4050\u001b[0m  0.0755\n",
            "     33      \u001b[36m363.2823\u001b[0m  0.0883\n",
            "     34      395.3409  0.0791\n",
            "     35      378.4197  0.0740\n",
            "     36      \u001b[36m336.3700\u001b[0m  0.0858\n",
            "     37      352.0914  0.1224\n",
            "     38      \u001b[36m314.1390\u001b[0m  0.0655\n",
            "     39      \u001b[36m249.5787\u001b[0m  0.1301\n",
            "     40      286.0315  0.0971\n",
            "     41      264.4909  0.1004\n",
            "     42      \u001b[36m249.3667\u001b[0m  0.0584\n",
            "     43      \u001b[36m235.7509\u001b[0m  0.0650\n",
            "     44      \u001b[36m219.7012\u001b[0m  0.0544\n",
            "     45      \u001b[36m210.5590\u001b[0m  0.0688\n",
            "     46      233.1437  0.0972\n",
            "     47      \u001b[36m202.1604\u001b[0m  0.0979\n",
            "     48      \u001b[36m187.1478\u001b[0m  0.1121\n",
            "     49      \u001b[36m181.3386\u001b[0m  0.1011\n",
            "     50      \u001b[36m166.2822\u001b[0m  0.0747\n",
            "     51      \u001b[36m151.8536\u001b[0m  0.0676\n",
            "     52      153.9548  0.0738\n",
            "     53      159.5092  0.1091\n",
            "     54      \u001b[36m124.6229\u001b[0m  0.0835\n",
            "     55      132.2114  0.0947\n",
            "     56      134.7463  0.0670\n",
            "     57      \u001b[36m115.1028\u001b[0m  0.0752\n",
            "     58      \u001b[36m109.7063\u001b[0m  0.0777\n",
            "     59      \u001b[36m109.6949\u001b[0m  0.0709\n",
            "     60       \u001b[36m98.8207\u001b[0m  0.0582\n",
            "     61       \u001b[36m90.1917\u001b[0m  0.0653\n",
            "     62       \u001b[36m83.5972\u001b[0m  0.0582\n",
            "     63       88.9322  0.0873\n",
            "     64       \u001b[36m74.1817\u001b[0m  0.0936\n",
            "     65       \u001b[36m66.1217\u001b[0m  0.0645\n",
            "     66       \u001b[36m60.0377\u001b[0m  0.0747\n",
            "     67       \u001b[36m57.7753\u001b[0m  0.0657\n",
            "     68       \u001b[36m53.3999\u001b[0m  0.0956\n",
            "     69       56.6070  0.0714\n",
            "     70       \u001b[36m42.8835\u001b[0m  0.0799\n",
            "     71       \u001b[36m40.8112\u001b[0m  0.0589\n",
            "     72       40.9728  0.0721\n",
            "     73       \u001b[36m34.7098\u001b[0m  0.0585\n",
            "     74       \u001b[36m33.8986\u001b[0m  0.0774\n",
            "     75       \u001b[36m26.8647\u001b[0m  0.0670\n",
            "     76       27.8162  0.0634\n",
            "     77       31.6257  0.0799\n",
            "     78       \u001b[36m23.3984\u001b[0m  0.0860\n",
            "     79       25.0035  0.0732\n",
            "     80       \u001b[36m20.0298\u001b[0m  0.0767\n",
            "     81       \u001b[36m16.9217\u001b[0m  0.0778\n",
            "     82       \u001b[36m16.1095\u001b[0m  0.0661\n",
            "     83       18.1520  0.0617\n",
            "     84       17.8181  0.1017\n",
            "     85       16.6632  0.0883\n",
            "     86       \u001b[36m10.3157\u001b[0m  0.0897\n",
            "     87        \u001b[36m9.4819\u001b[0m  0.0993\n",
            "     88       16.7130  0.0698\n",
            "     89       10.4470  0.0664\n",
            "     90       14.4821  0.1069\n",
            "     91        9.9776  0.0826\n",
            "     92        9.5766  0.0803\n",
            "     93        9.7568  0.0659\n",
            "     94       10.2159  0.0862\n",
            "     95        \u001b[36m6.1720\u001b[0m  0.0743\n",
            "     96        9.2804  0.0760\n",
            "     97        \u001b[36m4.1065\u001b[0m  0.0894\n",
            "     98        5.1348  0.0770\n",
            "     99        6.8787  0.1015\n",
            "    100        5.5293  0.1043\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m69395.0730\u001b[0m  0.0907\n",
            "      2    \u001b[36m55632.5542\u001b[0m  0.0929\n",
            "      3    \u001b[36m43819.8581\u001b[0m  0.0562\n",
            "      4    \u001b[36m34144.5696\u001b[0m  0.0693\n",
            "      5    \u001b[36m25934.1371\u001b[0m  0.0644\n",
            "      6    \u001b[36m18992.1081\u001b[0m  0.0684\n",
            "      7    \u001b[36m13069.4072\u001b[0m  0.0684\n",
            "      8     \u001b[36m8950.7154\u001b[0m  0.0784\n",
            "      9     \u001b[36m5014.5356\u001b[0m  0.0720\n",
            "     10     \u001b[36m3572.9241\u001b[0m  0.0834\n",
            "     11     \u001b[36m2723.5024\u001b[0m  0.0767\n",
            "     12     2907.6714  0.0779\n",
            "     13     2773.3944  0.0606\n",
            "     14     \u001b[36m2573.2462\u001b[0m  0.0883\n",
            "     15     \u001b[36m2464.6701\u001b[0m  0.1196\n",
            "     16     \u001b[36m2184.8006\u001b[0m  0.0930\n",
            "     17     \u001b[36m2084.3335\u001b[0m  0.1044\n",
            "     18     \u001b[36m1676.6399\u001b[0m  0.0700\n",
            "     19     1810.8847  0.0661\n",
            "     20     \u001b[36m1580.5709\u001b[0m  0.0895\n",
            "     21     1638.7522  0.0687\n",
            "     22     \u001b[36m1335.9774\u001b[0m  0.0632\n",
            "     23     \u001b[36m1234.4273\u001b[0m  0.0837\n",
            "     24     1332.1252  0.0706\n",
            "     25     1280.8844  0.1024\n",
            "     26     \u001b[36m1058.5033\u001b[0m  0.1025\n",
            "     27     \u001b[36m1033.8973\u001b[0m  0.0689\n",
            "     28     1061.8953  0.0765\n",
            "     29      \u001b[36m871.3523\u001b[0m  0.0690\n",
            "     30      \u001b[36m784.5847\u001b[0m  0.0588\n",
            "     31     1001.2132  0.1009\n",
            "     32      \u001b[36m749.1992\u001b[0m  0.0620\n",
            "     33      772.5731  0.0876\n",
            "     34      778.7431  0.0817\n",
            "     35      770.2430  0.0779\n",
            "     36      \u001b[36m598.8883\u001b[0m  0.0828\n",
            "     37      639.2326  0.0841\n",
            "     38      \u001b[36m503.4776\u001b[0m  0.0873\n",
            "     39      538.7679  0.0928\n",
            "     40      \u001b[36m473.6547\u001b[0m  0.0565\n",
            "     41      \u001b[36m439.6527\u001b[0m  0.0723\n",
            "     42      499.7765  0.0621\n",
            "     43      \u001b[36m438.1180\u001b[0m  0.0897\n",
            "     44      \u001b[36m403.2838\u001b[0m  0.0695\n",
            "     45      \u001b[36m353.8746\u001b[0m  0.0590\n",
            "     46      \u001b[36m349.8501\u001b[0m  0.0752\n",
            "     47      \u001b[36m306.7359\u001b[0m  0.0931\n",
            "     48      \u001b[36m289.6163\u001b[0m  0.0622\n",
            "     49      \u001b[36m279.1547\u001b[0m  0.0974\n",
            "     50      \u001b[36m263.8699\u001b[0m  0.0914\n",
            "     51      \u001b[36m217.5862\u001b[0m  0.0991\n",
            "     52      275.4795  0.0742\n",
            "     53      254.3020  0.0745\n",
            "     54      223.2592  0.0703\n",
            "     55      \u001b[36m184.8605\u001b[0m  0.0563\n",
            "     56      206.1999  0.0766\n",
            "     57      \u001b[36m162.4727\u001b[0m  0.0557\n",
            "     58      \u001b[36m157.7594\u001b[0m  0.0800\n",
            "     59      175.2755  0.0777\n",
            "     60      \u001b[36m136.3080\u001b[0m  0.0920\n",
            "     61      144.6782  0.0599\n",
            "     62      \u001b[36m130.7649\u001b[0m  0.0749\n",
            "     63      \u001b[36m111.8443\u001b[0m  0.0654\n",
            "     64      116.4638  0.1070\n",
            "     65      \u001b[36m104.3617\u001b[0m  0.0685\n",
            "     66       \u001b[36m85.5874\u001b[0m  0.0527\n",
            "     67      100.4314  0.0743\n",
            "     68       \u001b[36m83.9338\u001b[0m  0.1328\n",
            "     69       \u001b[36m82.5130\u001b[0m  0.0728\n",
            "     70       \u001b[36m74.5897\u001b[0m  0.0793\n",
            "     71       \u001b[36m67.0968\u001b[0m  0.0676\n",
            "     72       \u001b[36m61.0513\u001b[0m  0.0669\n",
            "     73       71.7703  0.0609\n",
            "     74       \u001b[36m56.7715\u001b[0m  0.0812\n",
            "     75       62.0145  0.0786\n",
            "     76       \u001b[36m54.1222\u001b[0m  0.0914\n",
            "     77       58.7689  0.0539\n",
            "     78       \u001b[36m51.7608\u001b[0m  0.0787\n",
            "     79       \u001b[36m41.2489\u001b[0m  0.0885\n",
            "     80       \u001b[36m40.8286\u001b[0m  0.0963\n",
            "     81       \u001b[36m37.0997\u001b[0m  0.0565\n",
            "     82       \u001b[36m33.9948\u001b[0m  0.1031\n",
            "     83       \u001b[36m32.6639\u001b[0m  0.0631\n",
            "     84       34.7616  0.0814\n",
            "     85       34.4733  0.0701\n",
            "     86       \u001b[36m26.1846\u001b[0m  0.0619\n",
            "     87       31.0330  0.0759\n",
            "     88       28.9346  0.0897\n",
            "     89       \u001b[36m18.1785\u001b[0m  0.0883\n",
            "     90       22.2802  0.0708\n",
            "     91       19.4581  0.0719\n",
            "     92       \u001b[36m14.9050\u001b[0m  0.0653\n",
            "     93       20.8829  0.0556\n",
            "     94       \u001b[36m12.7530\u001b[0m  0.0917\n",
            "     95       14.4678  0.0659\n",
            "     96       \u001b[36m12.5557\u001b[0m  0.0901\n",
            "     97       16.1421  0.0690\n",
            "     98       13.2519  0.0875\n",
            "     99       \u001b[36m10.0669\u001b[0m  0.1155\n",
            "    100       13.2672  0.0692\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m87511.2532\u001b[0m  0.0653\n",
            "      2    \u001b[36m69408.7160\u001b[0m  0.0689\n",
            "      3    \u001b[36m55116.2316\u001b[0m  0.0957\n",
            "      4    \u001b[36m43765.3725\u001b[0m  0.1044\n",
            "      5    \u001b[36m32980.1750\u001b[0m  0.0988\n",
            "      6    \u001b[36m26130.7360\u001b[0m  0.0602\n",
            "      7    \u001b[36m21966.2536\u001b[0m  0.0790\n",
            "      8    \u001b[36m16782.7555\u001b[0m  0.0850\n",
            "      9    \u001b[36m13004.0941\u001b[0m  0.0924\n",
            "     10     \u001b[36m9986.8018\u001b[0m  0.1165\n",
            "     11     \u001b[36m7293.0238\u001b[0m  0.0745\n",
            "     12     \u001b[36m4908.7912\u001b[0m  0.0765\n",
            "     13     \u001b[36m3136.4413\u001b[0m  0.0954\n",
            "     14     \u001b[36m1995.3536\u001b[0m  0.0926\n",
            "     15     \u001b[36m1437.8942\u001b[0m  0.0969\n",
            "     16     \u001b[36m1211.6895\u001b[0m  0.1240\n",
            "     17     1374.0415  0.1097\n",
            "     18     \u001b[36m1079.2319\u001b[0m  0.1097\n",
            "     19     \u001b[36m1060.2662\u001b[0m  0.0943\n",
            "     20     1163.3106  0.0835\n",
            "     21     1105.6010  0.0850\n",
            "     22      \u001b[36m998.3508\u001b[0m  0.1000\n",
            "     23      \u001b[36m780.7797\u001b[0m  0.0887\n",
            "     24      922.9501  0.0831\n",
            "     25      \u001b[36m753.9756\u001b[0m  0.1176\n",
            "     26      \u001b[36m707.2450\u001b[0m  0.1029\n",
            "     27      768.5067  0.1066\n",
            "     28      \u001b[36m626.4740\u001b[0m  0.0654\n",
            "     29      820.5075  0.0681\n",
            "     30      642.7240  0.0660\n",
            "     31      \u001b[36m499.6473\u001b[0m  0.0691\n",
            "     32      508.8233  0.0598\n",
            "     33      \u001b[36m456.1081\u001b[0m  0.0603\n",
            "     34      464.6363  0.0798\n",
            "     35      493.1775  0.0939\n",
            "     36      483.8654  0.0842\n",
            "     37      \u001b[36m381.4466\u001b[0m  0.0839\n",
            "     38      383.0465  0.0608\n",
            "     39      407.2977  0.0732\n",
            "     40      \u001b[36m349.2051\u001b[0m  0.0707\n",
            "     41      \u001b[36m324.9435\u001b[0m  0.0619\n",
            "     42      344.2033  0.0742\n",
            "     43      354.8446  0.0697\n",
            "     44      \u001b[36m276.0795\u001b[0m  0.1252\n",
            "     45      \u001b[36m226.9209\u001b[0m  0.0840\n",
            "     46      235.2044  0.0620\n",
            "     47      \u001b[36m212.4889\u001b[0m  0.0910\n",
            "     48      \u001b[36m187.8829\u001b[0m  0.0691\n",
            "     49      217.7397  0.0715\n",
            "     50      \u001b[36m172.9044\u001b[0m  0.0889\n",
            "     51      \u001b[36m171.1969\u001b[0m  0.0834\n",
            "     52      172.1742  0.0715\n",
            "     53      181.3441  0.1060\n",
            "     54      \u001b[36m159.2256\u001b[0m  0.0576\n",
            "     55      \u001b[36m154.8031\u001b[0m  0.0707\n",
            "     56      \u001b[36m137.2963\u001b[0m  0.0597\n",
            "     57      \u001b[36m126.8383\u001b[0m  0.0831\n",
            "     58      \u001b[36m108.4039\u001b[0m  0.1083\n",
            "     59      120.3142  0.0713\n",
            "     60      \u001b[36m102.8788\u001b[0m  0.0737\n",
            "     61       \u001b[36m93.4017\u001b[0m  0.0706\n",
            "     62       93.4669  0.0939\n",
            "     63       \u001b[36m87.1224\u001b[0m  0.0689\n",
            "     64       \u001b[36m70.9155\u001b[0m  0.0678\n",
            "     65       77.4544  0.1017\n",
            "     66       77.0272  0.0654\n",
            "     67       \u001b[36m67.1679\u001b[0m  0.0740\n",
            "     68       \u001b[36m64.3458\u001b[0m  0.0728\n",
            "     69       \u001b[36m60.6199\u001b[0m  0.0761\n",
            "     70       63.6471  0.0680\n",
            "     71       \u001b[36m48.4547\u001b[0m  0.0722\n",
            "     72       50.0720  0.0764\n",
            "     73       49.9670  0.0615\n",
            "     74       \u001b[36m46.8818\u001b[0m  0.0710\n",
            "     75       \u001b[36m45.2456\u001b[0m  0.0844\n",
            "     76       \u001b[36m42.4317\u001b[0m  0.0850\n",
            "     77       \u001b[36m31.3550\u001b[0m  0.0830\n",
            "     78       32.3273  0.0912\n",
            "     79       35.5260  0.0783\n",
            "     80       37.9090  0.0945\n",
            "     81       \u001b[36m26.3020\u001b[0m  0.0849\n",
            "     82       26.9337  0.0789\n",
            "     83       32.1082  0.0691\n",
            "     84       \u001b[36m24.0150\u001b[0m  0.0823\n",
            "     85       \u001b[36m16.0387\u001b[0m  0.0974\n",
            "     86       17.6546  0.0955\n",
            "     87       20.5608  0.1036\n",
            "     88       23.6934  0.0796\n",
            "     89       \u001b[36m15.6540\u001b[0m  0.0871\n",
            "     90       \u001b[36m14.0743\u001b[0m  0.0906\n",
            "     91       16.1688  0.0803\n",
            "     92        \u001b[36m9.5154\u001b[0m  0.0689\n",
            "     93       13.0996  0.0808\n",
            "     94        \u001b[36m8.6240\u001b[0m  0.0763\n",
            "     95        \u001b[36m7.9343\u001b[0m  0.0857\n",
            "     96        \u001b[36m7.0838\u001b[0m  0.0873\n",
            "     97        8.8830  0.0841\n",
            "     98        7.4262  0.0704\n",
            "     99        7.2326  0.0662\n",
            "    100        \u001b[36m3.4676\u001b[0m  0.1229\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m80077.1920\u001b[0m  0.0779\n",
            "      2    \u001b[36m64663.6333\u001b[0m  0.0820\n",
            "      3    \u001b[36m47354.8337\u001b[0m  0.0892\n",
            "      4    \u001b[36m37449.8052\u001b[0m  0.0819\n",
            "      5    \u001b[36m27403.1832\u001b[0m  0.0768\n",
            "      6    \u001b[36m18465.9145\u001b[0m  0.1135\n",
            "      7    \u001b[36m10626.5274\u001b[0m  0.0837\n",
            "      8     \u001b[36m5897.0855\u001b[0m  0.0801\n",
            "      9     \u001b[36m3682.2684\u001b[0m  0.0841\n",
            "     10     \u001b[36m3660.5451\u001b[0m  0.0650\n",
            "     11     \u001b[36m3470.7422\u001b[0m  0.0714\n",
            "     12     \u001b[36m2946.8919\u001b[0m  0.0882\n",
            "     13     \u001b[36m2738.2206\u001b[0m  0.0792\n",
            "     14     \u001b[36m2575.9757\u001b[0m  0.0680\n",
            "     15     2809.9809  0.0732\n",
            "     16     \u001b[36m2198.3106\u001b[0m  0.0755\n",
            "     17     \u001b[36m2093.6797\u001b[0m  0.0695\n",
            "     18     \u001b[36m2037.7624\u001b[0m  0.0789\n",
            "     19     \u001b[36m2000.7196\u001b[0m  0.0713\n",
            "     20     \u001b[36m1644.4518\u001b[0m  0.0677\n",
            "     21     1723.7225  0.0745\n",
            "     22     \u001b[36m1482.7336\u001b[0m  0.0981\n",
            "     23     1578.0579  0.0903\n",
            "     24     1502.3119  0.0690\n",
            "     25     \u001b[36m1434.0342\u001b[0m  0.0848\n",
            "     26     \u001b[36m1306.3436\u001b[0m  0.0823\n",
            "     27     \u001b[36m1235.0397\u001b[0m  0.0892\n",
            "     28     \u001b[36m1019.9474\u001b[0m  0.0689\n",
            "     29     1029.1996  0.0740\n",
            "     30      \u001b[36m859.3902\u001b[0m  0.0946\n",
            "     31      \u001b[36m831.3431\u001b[0m  0.0856\n",
            "     32      886.1757  0.0677\n",
            "     33      871.3522  0.0878\n",
            "     34      \u001b[36m777.5855\u001b[0m  0.0729\n",
            "     35      \u001b[36m619.7585\u001b[0m  0.0973\n",
            "     36      695.1998  0.0918\n",
            "     37      \u001b[36m591.1409\u001b[0m  0.0717\n",
            "     38      677.0651  0.0666\n",
            "     39      620.9248  0.0605\n",
            "     40      \u001b[36m517.1197\u001b[0m  0.0625\n",
            "     41      \u001b[36m450.8700\u001b[0m  0.0601\n",
            "     42      472.8493  0.0719\n",
            "     43      460.3999  0.0760\n",
            "     44      \u001b[36m430.6162\u001b[0m  0.0805\n",
            "     45      \u001b[36m420.2284\u001b[0m  0.0927\n",
            "     46      \u001b[36m398.7302\u001b[0m  0.0843\n",
            "     47      \u001b[36m367.2634\u001b[0m  0.1031\n",
            "     48      389.9765  0.0697\n",
            "     49      \u001b[36m311.8935\u001b[0m  0.0681\n",
            "     50      \u001b[36m308.4867\u001b[0m  0.0789\n",
            "     51      \u001b[36m303.9017\u001b[0m  0.0825\n",
            "     52      \u001b[36m273.9465\u001b[0m  0.0878\n",
            "     53      \u001b[36m245.4305\u001b[0m  0.0985\n",
            "     54      276.9330  0.0720\n",
            "     55      \u001b[36m225.1638\u001b[0m  0.0921\n",
            "     56      \u001b[36m192.1847\u001b[0m  0.0791\n",
            "     57      206.6512  0.0682\n",
            "     58      \u001b[36m187.6892\u001b[0m  0.0742\n",
            "     59      \u001b[36m181.4837\u001b[0m  0.0938\n",
            "     60      \u001b[36m152.2871\u001b[0m  0.0872\n",
            "     61      152.9266  0.0806\n",
            "     62      160.1283  0.0738\n",
            "     63      \u001b[36m133.4485\u001b[0m  0.1078\n",
            "     64      143.8730  0.0653\n",
            "     65      \u001b[36m112.7287\u001b[0m  0.0937\n",
            "     66      120.9328  0.0710\n",
            "     67      126.1538  0.1012\n",
            "     68      \u001b[36m108.4992\u001b[0m  0.0879\n",
            "     69       \u001b[36m89.2195\u001b[0m  0.0777\n",
            "     70       \u001b[36m80.3102\u001b[0m  0.0756\n",
            "     71       89.4734  0.0741\n",
            "     72       \u001b[36m73.0747\u001b[0m  0.0815\n",
            "     73       87.2555  0.0773\n",
            "     74       \u001b[36m65.2256\u001b[0m  0.0720\n",
            "     75       78.7351  0.0734\n",
            "     76       68.2224  0.0711\n",
            "     77       65.4205  0.0779\n",
            "     78       \u001b[36m49.5158\u001b[0m  0.0683\n",
            "     79       61.4036  0.1010\n",
            "     80       \u001b[36m46.8611\u001b[0m  0.0765\n",
            "     81       64.4517  0.0826\n",
            "     82       47.9491  0.0869\n",
            "     83       \u001b[36m44.8054\u001b[0m  0.0781\n",
            "     84       50.8357  0.0844\n",
            "     85       \u001b[36m40.4178\u001b[0m  0.0834\n",
            "     86       \u001b[36m40.0002\u001b[0m  0.0943\n",
            "     87       \u001b[36m36.5373\u001b[0m  0.0756\n",
            "     88       45.0138  0.0802\n",
            "     89       \u001b[36m33.8042\u001b[0m  0.0794\n",
            "     90       \u001b[36m31.7712\u001b[0m  0.0713\n",
            "     91       \u001b[36m29.0654\u001b[0m  0.0706\n",
            "     92       29.1985  0.1039\n",
            "     93       \u001b[36m26.7126\u001b[0m  0.0844\n",
            "     94       35.7217  0.0723\n",
            "     95       \u001b[36m26.2849\u001b[0m  0.0936\n",
            "     96       28.0692  0.0849\n",
            "     97       \u001b[36m23.1901\u001b[0m  0.0867\n",
            "     98       \u001b[36m21.8857\u001b[0m  0.0928\n",
            "     99       \u001b[36m20.5225\u001b[0m  0.0820\n",
            "    100       \u001b[36m19.6237\u001b[0m  0.0672\n"
          ]
        }
      ],
      "source": [
        "resultados = cross_val_score(classificador_sklearn, previsores, classe, cv = 10, scoring = 'accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUhUTS4vNTvD",
        "outputId": "96a8f148-2a76-48cd-8b36-259add42e722"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.6155075187969924, 0.10967042847071057)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "media = resultados.mean()\n",
        "desvio = resultados.std()\n",
        "media, desvio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNUs81ZJNfvb",
        "outputId": "ec6472e0-02af-440b-92d3-84471306673a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.68421053, 0.56140351, 0.59649123, 0.66666667, 0.66666667,\n",
              "       0.61403509, 0.43859649, 0.63157895, 0.45614035, 0.83928571])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "ename": "NotInitializedError",
          "evalue": "This NeuralNetBinaryClassifier instance is not initialized yet. Call 'initialize' or 'fit' with appropriate arguments before using this method.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/skorch/utils.py:588\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 588\u001b[0m     \u001b[43msk_check_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattributes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_or_any\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_or_any\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NotFittedError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1661\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[0;32m-> 1661\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
            "\u001b[0;31mNotFittedError\u001b[0m: This NeuralNetBinaryClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mNotInitializedError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[36], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m classe_treinamento \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./content/saidas-breast.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m previsores_teste \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39marray(previsores_treinamento), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[0;32m----> 7\u001b[0m previsoes \u001b[38;5;241m=\u001b[39m \u001b[43mclassificador_sklearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprevisores_teste\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m classe_treinamento \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(classe_treinamento)\n\u001b[1;32m     10\u001b[0m taxa_acerto \u001b[38;5;241m=\u001b[39m accuracy_score(classe, previsores)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/skorch/net.py:1486\u001b[0m, in \u001b[0;36mNeuralNet.forward\u001b[0;34m(self, X, training, device)\u001b[0m\n\u001b[1;32m   1444\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1445\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Gather and concatenate the output from forward call with\u001b[39;00m\n\u001b[1;32m   1446\u001b[0m \u001b[38;5;124;03m    input data.\u001b[39;00m\n\u001b[1;32m   1447\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1484\u001b[0m \n\u001b[1;32m   1485\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1486\u001b[0m     y_infer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1488\u001b[0m     is_multioutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(y_infer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y_infer[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mtuple\u001b[39m)\n\u001b[1;32m   1489\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_multioutput:\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/skorch/net.py:1441\u001b[0m, in \u001b[0;36mNeuralNet.forward_iter\u001b[0;34m(self, X, training, device)\u001b[0m\n\u001b[1;32m   1439\u001b[0m iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(dataset, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[1;32m   1440\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[0;32m-> 1441\u001b[0m     yp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1442\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m to_device(yp, device\u001b[38;5;241m=\u001b[39mdevice)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/skorch/net.py:1130\u001b[0m, in \u001b[0;36mNeuralNet.evaluation_step\u001b[0;34m(self, batch, training)\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluation_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform a forward step to produce the output used for\u001b[39;00m\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;124;03m    prediction and scoring.\u001b[39;00m\n\u001b[1;32m   1111\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \n\u001b[1;32m   1129\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m     Xi, _ \u001b[38;5;241m=\u001b[39m unpack_data(batch)\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(training):\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/skorch/net.py:1346\u001b[0m, in \u001b[0;36mNeuralNet.check_is_fitted\u001b[0;34m(self, attributes, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;66;03m# first check attributes argument, but if it's empty, check that the\u001b[39;00m\n\u001b[1;32m   1341\u001b[0m \u001b[38;5;66;03m# indicated _modules exist, and if those are not defined, assume that\u001b[39;00m\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;66;03m# the standard 'module_' attribute should exist\u001b[39;00m\n\u001b[1;32m   1343\u001b[0m attributes \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1344\u001b[0m     attributes \u001b[38;5;129;01mor\u001b[39;00m [module \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules] \u001b[38;5;129;01mor\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodule_\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m   1345\u001b[0m )\n\u001b[0;32m-> 1346\u001b[0m \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattributes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/skorch/utils.py:595\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m msg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    591\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m instance is not initialized yet. Call \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    592\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minitialize\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m with appropriate arguments \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    593\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbefore using this method.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 595\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m NotInitializedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m}) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
            "\u001b[0;31mNotInitializedError\u001b[0m: This NeuralNetBinaryClassifier instance is not initialized yet. Call 'initialize' or 'fit' with appropriate arguments before using this method."
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "previsores_treinamento = pd.read_csv('./content/entradas-breast.csv')\n",
        "classe_treinamento = pd.read_csv('./content/saidas-breast.csv')\n",
        "\n",
        "previsores_teste = torch.tensor(np.array(previsores_treinamento), dtype=torch.float)\n",
        "previsoes = classificador_sklearn.forward(previsores_teste)\n",
        "classe_treinamento = np.array(classe_treinamento)\n",
        "\n",
        "taxa_acerto = accuracy_score(classe, previsores)\n",
        "matriz = confusion_matrix(classe, previsores)\n",
        "sns.heatmap(matriz, annot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
